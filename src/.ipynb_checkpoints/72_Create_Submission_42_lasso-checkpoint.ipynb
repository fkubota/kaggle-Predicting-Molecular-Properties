{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- nb68で調べた特徴量を使ってみる\n",
    "- 標準化なしのdiffのみ\n",
    "- lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import multiprocessing\n",
    "import glob\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import linear_model\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 72\n",
    "isSmallSet = False\n",
    "length = 100000\n",
    "model_name = 'lasso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use atomic numbers to recode atomic names\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/champs-scalar-coupling/nb29_fc_test_feature.csv',\n",
       " '../input/champs-scalar-coupling/structures.zip',\n",
       " '../input/champs-scalar-coupling/nb47_fc_train.csv',\n",
       " '../input/champs-scalar-coupling/test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/train.csv',\n",
       " '../input/champs-scalar-coupling/scalar_coupling_contributions.csv',\n",
       " '../input/champs-scalar-coupling/test.csv',\n",
       " '../input/champs-scalar-coupling/nb33_train_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/structures.csv',\n",
       " '../input/champs-scalar-coupling/dipole_moments.csv',\n",
       " '../input/champs-scalar-coupling/potential_energy.csv',\n",
       " '../input/champs-scalar-coupling/nb33_test_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/magnetic_shielding_tensors.csv',\n",
       " '../input/champs-scalar-coupling/nb47_fc_test.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_train_feature.csv',\n",
       " '../input/champs-scalar-coupling/sample_submission.csv',\n",
       " '../input/champs-scalar-coupling/mulliken_charges.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../input/champs-scalar-coupling/'\n",
    "glob.glob(file_path + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "path = file_path + 'train.csv'\n",
    "if isSmallSet:\n",
    "    train = pd.read_csv(path) [:length]\n",
    "else:\n",
    "    train = pd.read_csv(path)\n",
    "    \n",
    "type_train = train.type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = file_path + 'test.csv'\n",
    "if isSmallSet:\n",
    "    test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    test = pd.read_csv(path)\n",
    "type_test = test.type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure\n",
    "path = file_path + 'structures.csv'\n",
    "structures = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_train\n",
    "path = file_path + 'nb47_fc_train.csv'\n",
    "if isSmallSet:\n",
    "    fc_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_test\n",
    "path = file_path + 'nb47_fc_test.csv'\n",
    "if isSmallSet:\n",
    "    fc_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge train\n",
    "path = file_path + 'train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_train = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_train = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge test\n",
    "path = file_path + 'test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_test = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_test = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 2505542)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(fc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 4658147)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(fc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4658147 rows in train data.\n",
      "There are 2505542 rows in test data.\n",
      "There are 85003 distinct molecules in train data.\n",
      "There are 45772 distinct molecules in test data.\n",
      "There are 29 unique atoms.\n",
      "There are 8 unique types.\n"
     ]
    }
   ],
   "source": [
    "if isSmallSet:\n",
    "    print('using SmallSet !!')\n",
    "    print('-------------------')\n",
    "\n",
    "print(f'There are {train.shape[0]} rows in train data.')\n",
    "print(f'There are {test.shape[0]} rows in test data.')\n",
    "\n",
    "print(f\"There are {train['molecule_name'].nunique()} distinct molecules in train data.\")\n",
    "print(f\"There are {test['molecule_name'].nunique()} distinct molecules in test data.\")\n",
    "print(f\"There are {train['atom_index_0'].nunique()} unique atoms.\")\n",
    "print(f\"There are {train['type'].nunique()} unique types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## myFunc\n",
    "**metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_metric(df, preds):\n",
    "    df[\"prediction\"] = preds\n",
    "    maes = []\n",
    "    for t in df.type.unique():\n",
    "        y_true = df[df.type==t].scalar_coupling_constant.values\n",
    "        y_pred = df[df.type==t].prediction.values\n",
    "        mae = np.log(mean_absolute_error(y_true, y_pred))\n",
    "        maes.append(mae)\n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**momory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, X_valid, y_valid):\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        self.base_score = self.metric(y_valid, self.model.predict(X_valid))\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(X_valid.columns):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            y_valid_pred = model.predict(df_perm)\n",
    "            score = self.metric(y_valid, y_valid_pred)\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# structure and ob_charges\n",
    "ob_charge = pd.concat([ob_charge_train, ob_charge_test])\n",
    "merge = pd.merge(ob_charge, structures, how='left',\n",
    "                  left_on  = ['molecule_name', 'atom_index'],\n",
    "                  right_on = ['molecule_name', 'atom_index'])\n",
    "for atom_idx in [0,1]:\n",
    "    train = map_atom_info(train, merge, atom_idx)\n",
    "    test  = map_atom_info(test,  merge, atom_idx)\n",
    "    \n",
    "    train = train.rename(columns={\n",
    "                                        'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}',\n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}',})\n",
    "    test = test.rename(columns={\n",
    "                                        'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}', \n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}'})\n",
    "#     test  =  test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "#                                         'x': f'x_{atom_idx}',\n",
    "#                                         'y': f'y_{atom_idx}',\n",
    "#                                         'z': f'z_{atom_idx}'})\n",
    "\n",
    "# ob_charges\n",
    "# train = map_atom_info(train, ob_charge_train, 0)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  0)\n",
    "# train = map_atom_info(train, ob_charge_train, 1)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "type0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type0(df):\n",
    "    df['type_0'] = df['type'].apply(lambda x : x[0])\n",
    "    return df\n",
    "# train['type_0'] = train['type'].apply(lambda x: x[0])\n",
    "# test['type_0'] = test['type'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(df):\n",
    "    df_p_0 = df[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df[['x_1', 'y_1', 'z_1']].values\n",
    "    \n",
    "    df['dist'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "    df['dist_x'] = (df['x_0'] - df['x_1']) ** 2\n",
    "    df['dist_y'] = (df['y_0'] - df['y_1']) ** 2\n",
    "    df['dist_z'] = (df['z_0'] - df['z_1']) ** 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "# train = distances(train)\n",
    "# test  = distances(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "統計量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "    # fc\n",
    "    df[f'molecule_type_fc_max'] = df.groupby(['molecule_name', 'type'])['fc'].transform('max')\n",
    "    df[f'molecule_type_fc_min'] = df.groupby(['molecule_name', 'type'])['fc'].transform('min')\n",
    "    df[f'molecule_type_fc_std'] = df.groupby(['molecule_name', 'type'])['fc'].transform('std')\n",
    "    df[f'molecule_type_fc_std_diff'] = df[f'molecule_type_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_fc_mean_diff'] = df[f'molecule_atom_index_0_fc_mean'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_mean_div'] = df[f'molecule_atom_index_0_fc_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_fc_max'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('max')\n",
    "    df[f'molecule_atom_index_0_fc_max_diff'] = df[f'molecule_atom_index_0_fc_max'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_max_div'] = df[f'molecule_atom_index_0_fc_max'] / df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_min'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('min')\n",
    "    df[f'molecule_atom_index_0_fc_min_diff'] = df[f'molecule_atom_index_0_fc_min'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_min_div'] = df[f'molecule_atom_index_0_fc_min'] / df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_std'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('std')\n",
    "    df[f'molecule_atom_index_0_fc_std_diff'] = df[f'molecule_atom_index_0_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_std_div'] = df[f'molecule_atom_index_0_fc_std'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_fc_mean_diff'] = df[f'molecule_atom_index_1_fc_mean'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_mean_div'] = df[f'molecule_atom_index_1_fc_mean'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_max'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('max')\n",
    "    df[f'molecule_atom_index_1_fc_max_diff'] = df[f'molecule_atom_index_1_fc_max'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_max_div'] = df[f'molecule_atom_index_1_fc_max'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_min'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('min')\n",
    "    df[f'molecule_atom_index_1_fc_min_diff'] = df[f'molecule_atom_index_1_fc_min'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_min_div'] = df[f'molecule_atom_index_1_fc_min'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_std'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('std')\n",
    "    df[f'molecule_atom_index_1_fc_std_diff'] = df[f'molecule_atom_index_1_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_std_div'] = df[f'molecule_atom_index_1_fc_std'] / df['fc']\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "angle features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_closest(df):\n",
    "    df_temp=df.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"dist\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"dist\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance', 'dist'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                        'x_closest': f'x_closest_{atom_idx}',\n",
    "                                        'y_closest': f'y_closest_{atom_idx}',\n",
    "                                        'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "def add_cos_features(df):\n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"dist\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"dist\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"dist\"]\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add fc\n",
      "4658147 2505542\n",
      "type0\n",
      "4658147 2505542\n",
      "distances\n",
      "4658147 2505542\n",
      "create_featueres\n",
      "4658147 2505542\n",
      "CPU times: user 2min 40s, sys: 3min 3s, total: 5min 43s\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('add fc')\n",
    "print(len(train), len(test))\n",
    "train['fc'] = fc_train.values\n",
    "test['fc']  = fc_test.values\n",
    "\n",
    "print('type0')\n",
    "print(len(train), len(test))\n",
    "train = create_type0(train)\n",
    "test  = create_type0(test)\n",
    "\n",
    "print('distances')\n",
    "print(len(train), len(test))\n",
    "train = distances(train)\n",
    "test  = distances(test)\n",
    "\n",
    "print('create_featueres')\n",
    "print(len(train), len(test))\n",
    "train = create_features(train)\n",
    "test  = create_features(test)\n",
    "\n",
    "# print('create_closest')\n",
    "# print(len(train), len(test))\n",
    "# train = create_closest(train)\n",
    "# test  = create_closest(test)\n",
    "# train.drop_duplicates(inplace=True, subset=['id'])   # なぜかtrainの行数が増えるバグが発生\n",
    "# train = train.reset_index(drop=True)\n",
    "\n",
    "# print('add_cos_features')\n",
    "# print(len(train), len(test))\n",
    "# train = add_cos_features(train)\n",
    "# test  = add_cos_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "nanがある特徴量を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['molecule_atom_index_0_x_1_std',\n",
       "       'molecule_atom_index_0_y_1_mean_div',\n",
       "       'molecule_atom_index_0_y_1_std', 'molecule_atom_index_0_z_1_std',\n",
       "       'molecule_atom_index_0_dist_std',\n",
       "       'molecule_atom_index_0_dist_std_diff',\n",
       "       'molecule_atom_index_0_dist_std_div',\n",
       "       'molecule_atom_index_1_dist_std',\n",
       "       'molecule_atom_index_1_dist_std_diff',\n",
       "       'molecule_atom_index_1_dist_std_div', 'molecule_atom_1_dist_std',\n",
       "       'molecule_atom_1_dist_std_diff', 'molecule_type_0_dist_std',\n",
       "       'molecule_type_0_dist_std_diff', 'molecule_type_dist_std',\n",
       "       'molecule_type_dist_std_diff', 'molecule_type_fc_std',\n",
       "       'molecule_type_fc_std_diff', 'molecule_atom_index_0_fc_std',\n",
       "       'molecule_atom_index_0_fc_std_diff',\n",
       "       'molecule_atom_index_0_fc_std_div', 'molecule_atom_index_1_fc_std',\n",
       "       'molecule_atom_index_1_fc_std_diff',\n",
       "       'molecule_atom_index_1_fc_std_div'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_feats = train.columns[train.isnull().sum(axis=0) != 0].values\n",
    "drop_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(drop_feats, axis=1)\n",
    "test  = test.drop(drop_feats, axis=1)\n",
    "\n",
    "assert sum(train.isnull().sum(axis=0))==0, f'train に nan があります。'\n",
    "assert sum(test.isnull().sum(axis=0))==0,  f'test に nan があります。'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "エンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリカル: ['atom_1']\n",
      "数値:        ['eem_0', 'molecule_type_dist_mean_div', 'molecule_atom_index_1_fc_min', 'z_1', 'molecule_atom_index_1_fc_mean_diff', 'dist_y', 'molecule_atom_index_1_fc_mean', 'gasteiger_0', 'molecule_atom_index_1_dist_mean_diff', 'molecule_atom_1_dist_mean', 'eem2015hm_0', 'eem2015hn_1', 'eem2015hn_0', 'molecule_atom_index_1_dist_min', 'atom_index_0', 'molecule_atom_index_1_fc_min_diff', 'molecule_atom_index_0_dist_mean_diff', 'molecule_type_dist_mean', 'molecule_atom_index_0_fc_mean_div', 'molecule_atom_1_dist_min_div', 'molecule_atom_index_0_fc_min', 'eem_1', 'molecule_atom_index_0_fc_min_div', 'molecule_atom_index_0_dist_min_diff', 'y_0', 'molecule_atom_index_1_dist_max_diff', 'molecule_atom_index_0_fc_max_diff', 'dist_x', 'x_1', 'eem2015bm_1', 'y_1', 'molecule_atom_index_1_fc_max_div', 'eem2015ba_0', 'molecule_atom_index_0_y_1_mean_diff', 'molecule_atom_index_0_y_1_max_diff', 'molecule_couples', 'molecule_atom_1_dist_min_diff', 'molecule_atom_index_0_dist_min_div', 'molecule_atom_index_0_dist_mean', 'molecule_atom_index_0_fc_min_diff', 'molecule_atom_index_1_fc_mean_div', 'molecule_type_dist_min', 'atom_index_1', 'z_0', 'molecule_dist_mean', 'molecule_type_dist_mean_diff', 'eem2015ha_0', 'molecule_atom_index_0_dist_min', 'molecule_atom_index_0_fc_mean_diff', 'molecule_atom_index_0_dist_max', 'molecule_atom_index_1_fc_min_div', 'qeq_1', 'eem2015ba_1', 'gasteiger_1', 'mmff94_0', 'qeq_0', 'qtpie_0', 'dist', 'type_0', 'dist_z', 'molecule_atom_index_0_dist_max_diff', 'eem2015bn_1', 'eem2015hm_1', 'molecule_atom_index_0_fc_max_div', 'molecule_atom_index_0_y_1_mean', 'molecule_type_dist_max', 'molecule_atom_index_1_dist_mean', 'qtpie_1', 'molecule_atom_index_1_fc_max_diff', 'molecule_type_fc_max', 'molecule_atom_index_0_dist_max_div', 'atom_0_couples_count', 'molecule_atom_index_1_dist_min_diff', 'molecule_dist_max', 'molecule_atom_index_1_dist_mean_div', 'molecule_type_fc_min', 'eem2015bn_0', 'eem2015ha_1', 'molecule_atom_index_1_dist_min_div', 'molecule_atom_index_0_y_1_max', 'molecule_atom_index_1_fc_max', 'eem2015bm_0', 'molecule_atom_1_dist_min', 'molecule_atom_index_0_dist_mean_div', 'x_0', 'molecule_atom_index_1_dist_max', 'molecule_atom_index_0_fc_mean', 'atom_1_couples_count', 'fc', 'molecule_atom_index_1_dist_max_div', 'mmff94_1', 'molecule_atom_index_0_fc_max', 'molecule_dist_min']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['atom_1']\n",
    "num_cols = list(set(train.columns) - set(cat_cols) - set(['type', \"scalar_coupling_constant\", 'molecule_name', 'id',\n",
    "                                                          'atom_0', 'atom_1','atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']))\n",
    "                \n",
    "print(f'カテゴリカル: {cat_cols}')\n",
    "print(f'数値:        {num_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "LabelEncode\n",
    "\n",
    "- `atom_1` = {H, C, N}\n",
    "- `type_0` = {1, 2, 3}\n",
    "- `type`   = {2JHC, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['type_0', 'type']:\n",
    "    if f in train.columns:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nb68で決めた特徴量を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feats =  [\n",
    " 'gasteiger_0',\n",
    " 'molecule_type_dist_min',\n",
    " 'mmff94_0',\n",
    " 'eem2015bn_0',\n",
    " 'eem2015hn_0',\n",
    " 'molecule_dist_min',\n",
    " 'eem2015hm_0',\n",
    " 'eem2015ba_0',\n",
    " 'eem_0',\n",
    " 'eem2015ha_0',\n",
    " 'gasteiger_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['scalar_coupling_constant']\n",
    "train = train[top10_feats+['fc']]\n",
    "test = test[top10_feats+['fc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12/12 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute\n",
    "for feat in progress_bar(train.columns):\n",
    "    train[f'fc-{feat}'] = train[feat].values - train.fc.values\n",
    "    test[f'fc-{feat}'] = test[feat].values - test.fc.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(top10_feats, axis=1)\n",
    "test = test.drop(top10_feats, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train[train.columns] = scaler.fit_transform(train)\n",
    "test[test.columns]   =  scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "LabelEncode\n",
    "\n",
    "- `atom_1` = {H, C, N}\n",
    "- `type_0` = {1, 2, 3}\n",
    "- `type`   = {2JHC, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['type'] = type_train\n",
    "test['type']  = type_test\n",
    "for f in ['type']:\n",
    "    if f in train.columns:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop(['id', 'molecule_name', 'atom_0', 'scalar_coupling_constant'], axis=1)\n",
    "# test  =  test.drop(['id', 'molecule_name', 'atom_0'], axis=1)\n",
    "# train = reduce_mem_usage(train)\n",
    "# test  = reduce_mem_usage(test)\n",
    "\n",
    "X = train.copy()\n",
    "X_test = test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MAX_ITER = 10000\n",
    "RANDOM_STATE = 3\n",
    "\n",
    "model_params_list = [\n",
    " {'alpha': 0.0001},\n",
    " {'alpha': 0.0001},\n",
    " {'alpha': 0.0001},\n",
    " {'alpha': 0.00026766168454752824},\n",
    " {'alpha': 0.00012790765937960229},\n",
    " {'alpha': 0.00016360369327968378},\n",
    " {'alpha': 0.0001},\n",
    " {'alpha': 0.00020926165473262722}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 6\n",
    "folds = KFold(n_splits=n_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, folds, model_params):\n",
    "    model = linear_model.Lasso(**model_params, max_iter=MAX_ITER, random_state=RANDOM_STATE)  # <=================\n",
    "\n",
    "    scores = []\n",
    "    oof = np.zeros(len(X))  \n",
    "    prediction = np.zeros(len(X))  \n",
    "    result_dict = {}\n",
    "    for fold_n, (train_idx, valid_idx) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        model.fit(X.iloc[train_idx, :], y[train_idx])\n",
    "        y_valid_pred = model.predict(X.iloc[valid_idx, :])\n",
    "        y_train_pred = model.predict(X.iloc[train_idx, :])\n",
    "        prediction = model.predict(X_test)\n",
    "        oof[valid_idx] = y_valid_pred\n",
    "        score = mean_absolute_error(y[valid_idx], y_valid_pred)\n",
    "        score_train = mean_absolute_error(y[train_idx], y_train_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "        print(f'fold {fold_n+1} train:{score_train :.5f} \\t valid: {score :.5f}')\n",
    "        print('')\n",
    "    print('CV mean score    : {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    print('kaggle mean score: {0:.4f}'.format(np.log(np.mean(scores)))) \n",
    "    print('')\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Training of type 0\n",
      "********************************************************************************\n",
      "Fold 1 started at Sun Aug 25 09:01:20 2019\n",
      "fold 1 train:0.74214 \t valid: 0.74102\n",
      "\n",
      "Fold 2 started at Sun Aug 25 09:07:33 2019\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# type ごとの学習 \n",
    "\n",
    "X_short = pd.DataFrame({'ind': list(X.index), 'type': X['type'].values, 'oof': [0] * len(X), 'target': y.values})\n",
    "X_short_test = pd.DataFrame({'ind': list(X_test.index), 'type': X_test['type'].values, 'prediction': [0] * len(X_test)})\n",
    "for t in X['type'].unique():\n",
    "    model_params = model_params_list[t]\n",
    "    print('*'*80)\n",
    "    print(f'Training of type {t}')\n",
    "    print('*'*80)\n",
    "    X_t = X.loc[X['type'] == t]\n",
    "    X_test_t = X_test.loc[X_test['type'] == t]\n",
    "    y_t = X_short.loc[X_short['type'] == t, 'target'].values\n",
    "    \n",
    "    result_dict = train_model(X_t, X_test_t, y_t, folds, model_params)\n",
    "    X_short.loc[X_short['type'] == t, 'oof'] = result_dict['oof']\n",
    "    X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict['prediction']\n",
    "    \n",
    "    \n",
    "\n",
    "print('')\n",
    "print('===== finish =====')\n",
    "X['scalar_coupling_constant'] = y\n",
    "metric = kaggle_metric(X, X_short['oof'])\n",
    "X = X.drop(['scalar_coupling_constant', 'prediction'], axis=1)\n",
    "print('CV mean score(group log mae): {0:.4f}'.format(metric))\n",
    "prediction = X_short_test['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_submittion = './output/' + 'nb{}_submission_lgb_{}.csv'.format(nb, metric)\n",
    "path_submittion = f'../output/nb{nb}_submission_{model_name}_{metric :.5f}.csv'\n",
    "print(f'save pash: {path_submittion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submittion = pd.read_csv('../input/champs-scalar-coupling/sample_submission.csv')\n",
    "# submittion = pd.read_csv('./input/champs-scalar-coupling/sample_submission.csv')[::100]\n",
    "submittion['scalar_coupling_constant'] = prediction\n",
    "if isSmallSet:\n",
    "    pass\n",
    "else:\n",
    "    submittion.to_csv(path_submittion, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_oof = f'../output/nb{nb}_oof_{model_name}_{metric :.5f}.csv'\n",
    "print(f'save pash: {path_oof}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.DataFrame(X_short['oof'])\n",
    "if isSmallSet:\n",
    "    pass\n",
    "else:\n",
    "    oof.to_csv(path_oof, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame(y)\n",
    "plot_data.index.name = 'id'\n",
    "plot_data['yhat'] = X_short['oof']\n",
    "plot_data['type'] = lbl.inverse_transform(X['type'])\n",
    "\n",
    "def plot_oof_preds(ctype, llim, ulim):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        sns.scatterplot(x='scalar_coupling_constant',y='yhat',\n",
    "                        data=plot_data.loc[plot_data['type']==ctype,\n",
    "                        ['scalar_coupling_constant', 'yhat']]);\n",
    "        plt.xlim((llim, ulim))\n",
    "        plt.ylim((llim, ulim))\n",
    "        plt.plot([llim, ulim], [llim, ulim])\n",
    "        plt.xlabel('scalar_coupling_constant')\n",
    "        plt.ylabel('predicted')\n",
    "        plt.title(f'{ctype}', fontsize=18)\n",
    "        plt.show()\n",
    "\n",
    "plot_oof_preds('1JHC', 0, 250)\n",
    "plot_oof_preds('1JHN', 0, 100)\n",
    "plot_oof_preds('2JHC', -50, 50)\n",
    "plot_oof_preds('2JHH', -50, 50)\n",
    "plot_oof_preds('2JHN', -25, 25)\n",
    "plot_oof_preds('3JHC', -25, 60)\n",
    "plot_oof_preds('3JHH', -20, 20)\n",
    "plot_oof_preds('3JHN', -10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

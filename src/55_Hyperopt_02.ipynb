{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- type ごとにハイパーパラメータ決める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import multiprocessing\n",
    "import glob\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 55\n",
    "isSmallSet = False\n",
    "length = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use atomic numbers to recode atomic names\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/champs-scalar-coupling/scalar_coupling_contributions.csv',\n",
       " '../input/champs-scalar-coupling/magnetic_shielding_tensors.csv',\n",
       " '../input/champs-scalar-coupling/structures.csv',\n",
       " '../input/champs-scalar-coupling/test.csv',\n",
       " '../input/champs-scalar-coupling/dipole_moments.csv',\n",
       " '../input/champs-scalar-coupling/potential_energy.csv',\n",
       " '../input/champs-scalar-coupling/sample_submission.csv',\n",
       " '../input/champs-scalar-coupling/nb47_fc_train.csv',\n",
       " '../input/champs-scalar-coupling/train.csv',\n",
       " '../input/champs-scalar-coupling/nb33_train_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_test_feature.csv',\n",
       " '../input/champs-scalar-coupling/train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/nb33_test_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/mulliken_charges.csv',\n",
       " '../input/champs-scalar-coupling/nb47_fc_test.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_train_feature.csv']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../input/champs-scalar-coupling/'\n",
    "glob.glob(file_path + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "path = file_path + 'train.csv'\n",
    "if isSmallSet:\n",
    "    train = pd.read_csv(path) [:length]\n",
    "else:\n",
    "    train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = file_path + 'test.csv'\n",
    "if isSmallSet:\n",
    "    test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure\n",
    "path = file_path + 'structures.csv'\n",
    "structures = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_train\n",
    "# path = file_path + 'nb47_fc_train.csv'\n",
    "path = file_path + 'nb29_fc_train_feature.csv'\n",
    "if isSmallSet:\n",
    "    fc_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_test\n",
    "# path = file_path + 'nb47_fc_test.csv'\n",
    "path = file_path + 'nb29_fc_test_feature.csv'\n",
    "if isSmallSet:\n",
    "    fc_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dist-interact\n",
    "path = file_path + 'nb33_train_dist-interaction.csv'\n",
    "if isSmallSet:\n",
    "    dist_interact_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    dist_interact_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dist-interact\n",
    "path = file_path + 'nb33_test_dist-interaction.csv'\n",
    "if isSmallSet:\n",
    "    dist_interact_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    dist_interact_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge train\n",
    "path = file_path + 'train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_train = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_train = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge test\n",
    "path = file_path + 'test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_test = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_test = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 2505542)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(fc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 4658147)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(fc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4658147 rows in train data.\n",
      "There are 2505542 rows in test data.\n",
      "There are 85003 distinct molecules in train data.\n",
      "There are 45772 distinct molecules in test data.\n",
      "There are 29 unique atoms.\n",
      "There are 8 unique types.\n"
     ]
    }
   ],
   "source": [
    "if isSmallSet:\n",
    "    print('using SmallSet !!')\n",
    "    print('-------------------')\n",
    "\n",
    "print(f'There are {train.shape[0]} rows in train data.')\n",
    "print(f'There are {test.shape[0]} rows in test data.')\n",
    "\n",
    "print(f\"There are {train['molecule_name'].nunique()} distinct molecules in train data.\")\n",
    "print(f\"There are {test['molecule_name'].nunique()} distinct molecules in test data.\")\n",
    "print(f\"There are {train['atom_index_0'].nunique()} unique atoms.\")\n",
    "print(f\"There are {train['type'].nunique()} unique types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## myFunc\n",
    "**metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_metric(df, preds):\n",
    "    df[\"prediction\"] = preds\n",
    "    maes = []\n",
    "    for t in df.type.unique():\n",
    "        y_true = df[df.type==t].scalar_coupling_constant.values\n",
    "        y_pred = df[df.type==t].prediction.values\n",
    "        mae = np.log(mean_absolute_error(y_true, y_pred))\n",
    "        maes.append(mae)\n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**momory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Distance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_name'].isin(base['molecule_name'])]\n",
    "    return base, structures\n",
    "\n",
    "# a,b = build_type_dataframes(train, structures, '1JHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_name', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_name', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_name', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_name'],\n",
    "                  right_on=['molecule_name'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        (df['x_c'] - df['x'])**np.float32(2) +\n",
    "        (df['y_c'] - df['y'])**np.float32(2) + \n",
    "        (df['z_c'] - df['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_name'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_name', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_name', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_name', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "#     # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "#     atoms['molecule_name'] = atoms['molecule_name'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = ['id', 'molecule_name', 'atom_index_1', 'atom_index_0']\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    return df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8/8 07:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "atoms = structures['atom'].values\n",
    "types_train = train['type'].values\n",
    "types_test = test['type'].values\n",
    "structures['atom'] = structures['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "fulls_train = []\n",
    "fulls_test  = []\n",
    "for type_ in progress_bar(train['type'].unique()):\n",
    "    full_train = build_couple_dataframe(train, structures, type_, n_atoms=10)\n",
    "    full_test  = build_couple_dataframe(test, structures, type_, n_atoms=10)\n",
    "    full_train = take_n_atoms(full_train, 10)\n",
    "    full_test  = take_n_atoms(full_test, 10)\n",
    "    fulls_train.append(full_train)\n",
    "    fulls_test.append(full_test)\n",
    "    \n",
    "structures['atom'] = atoms\n",
    "train = pd.concat(fulls_train).sort_values(by=['id']) #, axis=0)\n",
    "test  = pd.concat(fulls_test).sort_values(by=['id']) #, axis=0)\n",
    "train['type'] = types_train\n",
    "test['type'] = types_test\n",
    "train = train.fillna(0)\n",
    "test  = test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "dist-interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dist_interact'] = dist_interact_train.values\n",
    "test['dist_interact'] = dist_interact_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>d_1_0</th>\n",
       "      <th>d_2_0</th>\n",
       "      <th>d_2_1</th>\n",
       "      <th>d_3_0</th>\n",
       "      <th>d_3_1</th>\n",
       "      <th>d_3_2</th>\n",
       "      <th>d_4_0</th>\n",
       "      <th>d_4_1</th>\n",
       "      <th>d_4_2</th>\n",
       "      <th>d_4_3</th>\n",
       "      <th>d_5_0</th>\n",
       "      <th>d_5_1</th>\n",
       "      <th>d_5_2</th>\n",
       "      <th>d_5_3</th>\n",
       "      <th>d_6_0</th>\n",
       "      <th>d_6_1</th>\n",
       "      <th>d_6_2</th>\n",
       "      <th>d_6_3</th>\n",
       "      <th>d_7_0</th>\n",
       "      <th>d_7_1</th>\n",
       "      <th>d_7_2</th>\n",
       "      <th>d_7_3</th>\n",
       "      <th>d_8_0</th>\n",
       "      <th>d_8_1</th>\n",
       "      <th>d_8_2</th>\n",
       "      <th>d_8_3</th>\n",
       "      <th>d_9_0</th>\n",
       "      <th>d_9_1</th>\n",
       "      <th>d_9_2</th>\n",
       "      <th>d_9_3</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>type</th>\n",
       "      <th>dist_interact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>1.091953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>2.183905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>2.183899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>2.183901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>1.091952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_1  atom_index_0  atom_2  atom_3  atom_4  \\\n",
       "0   0  dsgdb9nsd_000001             0             1       1       1       1   \n",
       "0   1  dsgdb9nsd_000001             2             1       6       1       1   \n",
       "1   2  dsgdb9nsd_000001             3             1       6       1       1   \n",
       "3   3  dsgdb9nsd_000001             4             1       6       1       1   \n",
       "1   4  dsgdb9nsd_000001             0             2       1       1       1   \n",
       "\n",
       "   atom_5  atom_6  atom_7  atom_8  atom_9     d_1_0     d_2_0     d_2_1  \\\n",
       "0       0       0       0       0       0  1.091953  1.783120  1.091952   \n",
       "0       0       0       0       0       0  1.783120  1.091953  1.091952   \n",
       "1       0       0       0       0       0  1.783147  1.091953  1.091946   \n",
       "3       0       0       0       0       0  1.783157  1.091953  1.091948   \n",
       "1       0       0       0       0       0  1.091952  1.783120  1.091953   \n",
       "\n",
       "      d_3_0     d_3_1     d_3_2     d_4_0     d_4_1     d_4_2     d_4_3  \\\n",
       "0  1.783147  1.091946  1.783158  1.783157  1.091948  1.783148  1.783148   \n",
       "0  1.783157  1.783148  1.091948  1.783147  1.783158  1.091946  1.783148   \n",
       "1  1.783120  1.783158  1.091952  1.783157  1.783148  1.091948  1.783148   \n",
       "3  1.783120  1.783148  1.091952  1.783147  1.783148  1.091946  1.783158   \n",
       "1  1.783148  1.091948  1.783157  1.783158  1.091946  1.783147  1.783148   \n",
       "\n",
       "   d_5_0  d_5_1  d_5_2  d_5_3  d_6_0  d_6_1  d_6_2  d_6_3  d_7_0  d_7_1  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   d_7_2  d_7_3  d_8_0  d_8_1  d_8_2  d_8_3  d_9_0  d_9_1  d_9_2  d_9_3  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   scalar_coupling_constant  type  dist_interact  \n",
       "0                   84.8076  1JHC       1.091953  \n",
       "0                  -11.2570  2JHH       2.183905  \n",
       "1                  -11.2548  2JHH       2.183899  \n",
       "3                  -11.2543  2JHH       2.183901  \n",
       "1                   84.8074  1JHC       1.091952  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# structure and ob_charges\n",
    "ob_charge = pd.concat([ob_charge_train, ob_charge_test])\n",
    "merge = pd.merge(ob_charge, structures, how='left',\n",
    "                  left_on  = ['molecule_name', 'atom_index'],\n",
    "                  right_on = ['molecule_name', 'atom_index'])\n",
    "for atom_idx in [0,1]:\n",
    "    train = map_atom_info(train, merge, atom_idx)\n",
    "    test  = map_atom_info(test,  merge, atom_idx)\n",
    "    \n",
    "    train = train.rename(columns={\n",
    "                                        'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}',\n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}',})\n",
    "    test = test.rename(columns={\n",
    "                                        'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}', \n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}'})\n",
    "#     test  =  test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "#                                         'x': f'x_{atom_idx}',\n",
    "#                                         'y': f'y_{atom_idx}',\n",
    "#                                         'z': f'z_{atom_idx}'})\n",
    "\n",
    "# ob_charges\n",
    "# train = map_atom_info(train, ob_charge_train, 0)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  0)\n",
    "# train = map_atom_info(train, ob_charge_train, 1)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "type0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type0(df):\n",
    "    df['type_0'] = df['type'].apply(lambda x : x[0])\n",
    "    return df\n",
    "# train['type_0'] = train['type'].apply(lambda x: x[0])\n",
    "# test['type_0'] = test['type'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(df):\n",
    "    df_p_0 = df[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df[['x_1', 'y_1', 'z_1']].values\n",
    "    \n",
    "    df['dist'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "    df['dist_x'] = (df['x_0'] - df['x_1']) ** 2\n",
    "    df['dist_y'] = (df['y_0'] - df['y_1']) ** 2\n",
    "    df['dist_z'] = (df['z_0'] - df['z_1']) ** 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "# train = distances(train)\n",
    "# test  = distances(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "統計量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "    # fc\n",
    "    df[f'molecule_type_fc_max'] = df.groupby(['molecule_name', 'type'])['fc'].transform('max')\n",
    "    df[f'molecule_type_fc_min'] = df.groupby(['molecule_name', 'type'])['fc'].transform('min')\n",
    "    df[f'molecule_type_fc_std'] = df.groupby(['molecule_name', 'type'])['fc'].transform('std')\n",
    "    df[f'molecule_type_fc_std_diff'] = df[f'molecule_type_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_fc_mean_diff'] = df[f'molecule_atom_index_0_fc_mean'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_mean_div'] = df[f'molecule_atom_index_0_fc_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_fc_max'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('max')\n",
    "    df[f'molecule_atom_index_0_fc_max_diff'] = df[f'molecule_atom_index_0_fc_max'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_max_div'] = df[f'molecule_atom_index_0_fc_max'] / df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_min'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('min')\n",
    "    df[f'molecule_atom_index_0_fc_min_diff'] = df[f'molecule_atom_index_0_fc_min'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_min_div'] = df[f'molecule_atom_index_0_fc_min'] / df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_std'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('std')\n",
    "    df[f'molecule_atom_index_0_fc_std_diff'] = df[f'molecule_atom_index_0_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_std_div'] = df[f'molecule_atom_index_0_fc_std'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_fc_mean_diff'] = df[f'molecule_atom_index_1_fc_mean'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_mean_div'] = df[f'molecule_atom_index_1_fc_mean'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_max'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('max')\n",
    "    df[f'molecule_atom_index_1_fc_max_diff'] = df[f'molecule_atom_index_1_fc_max'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_max_div'] = df[f'molecule_atom_index_1_fc_max'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_min'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('min')\n",
    "    df[f'molecule_atom_index_1_fc_min_diff'] = df[f'molecule_atom_index_1_fc_min'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_min_div'] = df[f'molecule_atom_index_1_fc_min'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_std'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('std')\n",
    "    df[f'molecule_atom_index_1_fc_std_diff'] = df[f'molecule_atom_index_1_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_std_div'] = df[f'molecule_atom_index_1_fc_std'] / df['fc']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "angle features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_closest(df):\n",
    "    df_temp=df.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"dist\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"dist\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance', 'dist'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                        'x_closest': f'x_closest_{atom_idx}',\n",
    "                                        'y_closest': f'y_closest_{atom_idx}',\n",
    "                                        'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "def add_cos_features(df):\n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"dist\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"dist\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"dist\"]\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add fc\n",
      "4658147 2505542\n",
      "type0\n",
      "4658147 2505542\n",
      "distances\n",
      "4658147 2505542\n",
      "create_featueres\n",
      "4658147 2505542\n",
      "create_closest\n",
      "4658147 2505542\n",
      "add_cos_features\n",
      "4658147 2505542\n",
      "CPU times: user 3min 2s, sys: 4min 40s, total: 7min 43s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('add fc')\n",
    "print(len(train), len(test))\n",
    "train['fc'] = fc_train.values\n",
    "test['fc']  = fc_test.values\n",
    "\n",
    "print('type0')\n",
    "print(len(train), len(test))\n",
    "train = create_type0(train)\n",
    "test  = create_type0(test)\n",
    "\n",
    "print('distances')\n",
    "print(len(train), len(test))\n",
    "train = distances(train)\n",
    "test  = distances(test)\n",
    "\n",
    "print('create_featueres')\n",
    "print(len(train), len(test))\n",
    "train = create_features(train)\n",
    "test  = create_features(test)\n",
    "\n",
    "print('create_closest')\n",
    "print(len(train), len(test))\n",
    "train = create_closest(train)\n",
    "test  = create_closest(test)\n",
    "train.drop_duplicates(inplace=True, subset=['id'])   # なぜかtrainの行数が増えるバグが発生\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "print('add_cos_features')\n",
    "print(len(train), len(test))\n",
    "train = add_cos_features(train)\n",
    "test  = add_cos_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "<br>\n",
    "LabelEncode\n",
    "\n",
    "- `atom_1` = {H, C, N}\n",
    "- `type_0` = {1, 2, 3}\n",
    "- `type`   = {2JHC, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['atom_1', 'type_0', 'type']:\n",
    "    if f in train.columns:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**show features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>d_1_0</th>\n",
       "      <th>d_2_0</th>\n",
       "      <th>d_2_1</th>\n",
       "      <th>d_3_0</th>\n",
       "      <th>d_3_1</th>\n",
       "      <th>d_3_2</th>\n",
       "      <th>d_4_0</th>\n",
       "      <th>d_4_1</th>\n",
       "      <th>d_4_2</th>\n",
       "      <th>d_4_3</th>\n",
       "      <th>d_5_0</th>\n",
       "      <th>d_5_1</th>\n",
       "      <th>d_5_2</th>\n",
       "      <th>d_5_3</th>\n",
       "      <th>d_6_0</th>\n",
       "      <th>d_6_1</th>\n",
       "      <th>d_6_2</th>\n",
       "      <th>d_6_3</th>\n",
       "      <th>d_7_0</th>\n",
       "      <th>d_7_1</th>\n",
       "      <th>d_7_2</th>\n",
       "      <th>d_7_3</th>\n",
       "      <th>d_8_0</th>\n",
       "      <th>d_8_1</th>\n",
       "      <th>d_8_2</th>\n",
       "      <th>d_8_3</th>\n",
       "      <th>d_9_0</th>\n",
       "      <th>d_9_1</th>\n",
       "      <th>d_9_2</th>\n",
       "      <th>d_9_3</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>type</th>\n",
       "      <th>dist_interact</th>\n",
       "      <th>eem_0</th>\n",
       "      <th>mmff94_0</th>\n",
       "      <th>gasteiger_0</th>\n",
       "      <th>qeq_0</th>\n",
       "      <th>qtpie_0</th>\n",
       "      <th>eem2015ha_0</th>\n",
       "      <th>eem2015hm_0</th>\n",
       "      <th>eem2015hn_0</th>\n",
       "      <th>eem2015ba_0</th>\n",
       "      <th>eem2015bm_0</th>\n",
       "      <th>eem2015bn_0</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>eem_1</th>\n",
       "      <th>mmff94_1</th>\n",
       "      <th>gasteiger_1</th>\n",
       "      <th>qeq_1</th>\n",
       "      <th>qtpie_1</th>\n",
       "      <th>eem2015ha_1</th>\n",
       "      <th>eem2015hm_1</th>\n",
       "      <th>eem2015hn_1</th>\n",
       "      <th>eem2015ba_1</th>\n",
       "      <th>eem2015bm_1</th>\n",
       "      <th>eem2015bn_1</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>fc</th>\n",
       "      <th>type_0</th>\n",
       "      <th>dist</th>\n",
       "      <th>dist_x</th>\n",
       "      <th>dist_y</th>\n",
       "      <th>dist_z</th>\n",
       "      <th>molecule_couples</th>\n",
       "      <th>molecule_dist_mean</th>\n",
       "      <th>molecule_dist_min</th>\n",
       "      <th>molecule_dist_max</th>\n",
       "      <th>atom_0_couples_count</th>\n",
       "      <th>atom_1_couples_count</th>\n",
       "      <th>molecule_atom_index_0_x_1_std</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean_div</th>\n",
       "      <th>molecule_atom_index_0_y_1_max</th>\n",
       "      <th>molecule_atom_index_0_y_1_max_diff</th>\n",
       "      <th>molecule_atom_index_0_y_1_std</th>\n",
       "      <th>molecule_atom_index_0_z_1_std</th>\n",
       "      <th>molecule_atom_index_0_dist_mean</th>\n",
       "      <th>molecule_atom_index_0_dist_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_mean_div</th>\n",
       "      <th>molecule_atom_index_0_dist_max</th>\n",
       "      <th>molecule_atom_index_0_dist_max_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_max_div</th>\n",
       "      <th>molecule_atom_index_0_dist_min</th>\n",
       "      <th>molecule_atom_index_0_dist_min_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_min_div</th>\n",
       "      <th>molecule_atom_index_0_dist_std</th>\n",
       "      <th>molecule_atom_index_0_dist_std_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_std_div</th>\n",
       "      <th>molecule_atom_index_1_dist_mean</th>\n",
       "      <th>molecule_atom_index_1_dist_mean_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_mean_div</th>\n",
       "      <th>molecule_atom_index_1_dist_max</th>\n",
       "      <th>molecule_atom_index_1_dist_max_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_max_div</th>\n",
       "      <th>molecule_atom_index_1_dist_min</th>\n",
       "      <th>molecule_atom_index_1_dist_min_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_min_div</th>\n",
       "      <th>molecule_atom_index_1_dist_std</th>\n",
       "      <th>molecule_atom_index_1_dist_std_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_std_div</th>\n",
       "      <th>molecule_atom_1_dist_mean</th>\n",
       "      <th>molecule_atom_1_dist_min</th>\n",
       "      <th>molecule_atom_1_dist_min_diff</th>\n",
       "      <th>molecule_atom_1_dist_min_div</th>\n",
       "      <th>molecule_atom_1_dist_std</th>\n",
       "      <th>molecule_atom_1_dist_std_diff</th>\n",
       "      <th>molecule_type_0_dist_std</th>\n",
       "      <th>molecule_type_0_dist_std_diff</th>\n",
       "      <th>molecule_type_dist_mean</th>\n",
       "      <th>molecule_type_dist_mean_diff</th>\n",
       "      <th>molecule_type_dist_mean_div</th>\n",
       "      <th>molecule_type_dist_max</th>\n",
       "      <th>molecule_type_dist_min</th>\n",
       "      <th>molecule_type_dist_std</th>\n",
       "      <th>molecule_type_dist_std_diff</th>\n",
       "      <th>molecule_type_fc_max</th>\n",
       "      <th>molecule_type_fc_min</th>\n",
       "      <th>molecule_type_fc_std</th>\n",
       "      <th>molecule_type_fc_std_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_mean</th>\n",
       "      <th>molecule_atom_index_0_fc_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_mean_div</th>\n",
       "      <th>molecule_atom_index_0_fc_max</th>\n",
       "      <th>molecule_atom_index_0_fc_max_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_max_div</th>\n",
       "      <th>molecule_atom_index_0_fc_min</th>\n",
       "      <th>molecule_atom_index_0_fc_min_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_min_div</th>\n",
       "      <th>molecule_atom_index_0_fc_std</th>\n",
       "      <th>molecule_atom_index_0_fc_std_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_std_div</th>\n",
       "      <th>molecule_atom_index_1_fc_mean</th>\n",
       "      <th>molecule_atom_index_1_fc_mean_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_mean_div</th>\n",
       "      <th>molecule_atom_index_1_fc_max</th>\n",
       "      <th>molecule_atom_index_1_fc_max_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_max_div</th>\n",
       "      <th>molecule_atom_index_1_fc_min</th>\n",
       "      <th>molecule_atom_index_1_fc_min_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_min_div</th>\n",
       "      <th>molecule_atom_index_1_fc_std</th>\n",
       "      <th>molecule_atom_index_1_fc_std_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_std_div</th>\n",
       "      <th>atom_index_closest_0</th>\n",
       "      <th>x_closest_0</th>\n",
       "      <th>y_closest_0</th>\n",
       "      <th>z_closest_0</th>\n",
       "      <th>atom_index_closest_1</th>\n",
       "      <th>x_closest_1</th>\n",
       "      <th>y_closest_1</th>\n",
       "      <th>z_closest_1</th>\n",
       "      <th>distance_0</th>\n",
       "      <th>distance_1</th>\n",
       "      <th>cos_0_1</th>\n",
       "      <th>cos_0</th>\n",
       "      <th>cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>-0.812772</td>\n",
       "      <td>0.773439</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.196234</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.201583</td>\n",
       "      <td>0.212813</td>\n",
       "      <td>H</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.644531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077596</td>\n",
       "      <td>3.251140</td>\n",
       "      <td>-3.093807</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>-0.813021</td>\n",
       "      <td>-0.784944</td>\n",
       "      <td>-0.067349</td>\n",
       "      <td>-0.806339</td>\n",
       "      <td>-0.851258</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>83.534069</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1.192105</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>10</td>\n",
       "      <td>1.506668</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.727907</td>\n",
       "      <td>1.358754</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>1.251380</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.182278</td>\n",
       "      <td>0.727957</td>\n",
       "      <td>1.610344</td>\n",
       "      <td>0.518391</td>\n",
       "      <td>1.474738</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>0.691204</td>\n",
       "      <td>1.632998</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345594</td>\n",
       "      <td>-0.746359</td>\n",
       "      <td>0.316492</td>\n",
       "      <td>1.09195</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.09195</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.091950</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>1.091950</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>87.113102</td>\n",
       "      <td>83.162207</td>\n",
       "      <td>1.799476</td>\n",
       "      <td>-81.734593</td>\n",
       "      <td>12.402786</td>\n",
       "      <td>-71.131284</td>\n",
       "      <td>11.358351</td>\n",
       "      <td>83.534069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>-95.226114</td>\n",
       "      <td>-0.139967</td>\n",
       "      <td>47.422338</td>\n",
       "      <td>-36.111731</td>\n",
       "      <td>0.567701</td>\n",
       "      <td>84.475574</td>\n",
       "      <td>0.941505</td>\n",
       "      <td>1.011271</td>\n",
       "      <td>87.113102</td>\n",
       "      <td>3.579033</td>\n",
       "      <td>1.042845</td>\n",
       "      <td>83.162207</td>\n",
       "      <td>-0.371863</td>\n",
       "      <td>0.995548</td>\n",
       "      <td>1.799476</td>\n",
       "      <td>-81.734593</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>3</td>\n",
       "      <td>2.183905</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>-0.812772</td>\n",
       "      <td>0.773439</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.196234</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.201583</td>\n",
       "      <td>0.212813</td>\n",
       "      <td>H</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.161132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>-0.812776</td>\n",
       "      <td>0.773442</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.196235</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.201584</td>\n",
       "      <td>0.212813</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>1</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.019253</td>\n",
       "      <td>2.160261</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>10</td>\n",
       "      <td>1.506668</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727907</td>\n",
       "      <td>1.358754</td>\n",
       "      <td>-0.104998</td>\n",
       "      <td>0.928268</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182278</td>\n",
       "      <td>0.727957</td>\n",
       "      <td>1.610344</td>\n",
       "      <td>-0.172776</td>\n",
       "      <td>0.903105</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>1.000021</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>-0.691167</td>\n",
       "      <td>0.612383</td>\n",
       "      <td>0.345594</td>\n",
       "      <td>-1.437526</td>\n",
       "      <td>0.193814</td>\n",
       "      <td>1.78312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.783146</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783106</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783106</td>\n",
       "      <td>1.783146</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.000015</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783106</td>\n",
       "      <td>-10.558171</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>0.452166</td>\n",
       "      <td>12.144210</td>\n",
       "      <td>12.402786</td>\n",
       "      <td>24.094830</td>\n",
       "      <td>6.955666</td>\n",
       "      <td>83.534069</td>\n",
       "      <td>95.226114</td>\n",
       "      <td>-7.144522</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.422338</td>\n",
       "      <td>59.114383</td>\n",
       "      <td>-4.055949</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-11.692044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>-0.333287</td>\n",
       "      <td>-0.816483</td>\n",
       "      <td>0.816482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_1  atom_index_0  atom_2  atom_3  atom_4  \\\n",
       "0   0  dsgdb9nsd_000001             0             1       1       1       1   \n",
       "1   1  dsgdb9nsd_000001             2             1       6       1       1   \n",
       "\n",
       "   atom_5  atom_6  atom_7  atom_8  atom_9     d_1_0     d_2_0     d_2_1  \\\n",
       "0       0       0       0       0       0  1.091953  1.783120  1.091952   \n",
       "1       0       0       0       0       0  1.783120  1.091953  1.091952   \n",
       "\n",
       "      d_3_0     d_3_1     d_3_2     d_4_0     d_4_1     d_4_2     d_4_3  \\\n",
       "0  1.783147  1.091946  1.783158  1.783157  1.091948  1.783148  1.783148   \n",
       "1  1.783157  1.783148  1.091948  1.783147  1.783158  1.091946  1.783148   \n",
       "\n",
       "   d_5_0  d_5_1  d_5_2  d_5_3  d_6_0  d_6_1  d_6_2  d_6_3  d_7_0  d_7_1  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   d_7_2  d_7_3  d_8_0  d_8_1  d_8_2  d_8_3  d_9_0  d_9_1  d_9_2  d_9_3  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   scalar_coupling_constant  type  dist_interact     eem_0  mmff94_0  \\\n",
       "0                   84.8076     0       1.091953  0.161131       0.0   \n",
       "1                  -11.2570     3       2.183905  0.161131       0.0   \n",
       "\n",
       "   gasteiger_0     qeq_0   qtpie_0  eem2015ha_0  eem2015hm_0  eem2015hn_0  \\\n",
       "0     0.019399 -0.812772  0.773439    -0.003651     0.203254     0.196234   \n",
       "1     0.019399 -0.812772  0.773439    -0.003651     0.203254     0.196234   \n",
       "\n",
       "   eem2015ba_0  eem2015bm_0  eem2015bn_0 atom_0      x_0       y_0       z_0  \\\n",
       "0     0.016837     0.201583     0.212813      H  0.00215 -0.006031  0.001976   \n",
       "1     0.016837     0.201583     0.212813      H  0.00215 -0.006031  0.001976   \n",
       "\n",
       "      eem_1  mmff94_1  gasteiger_1     qeq_1   qtpie_1  eem2015ha_1  \\\n",
       "0 -0.644531       0.0    -0.077596  3.251140 -3.093807     0.014606   \n",
       "1  0.161132       0.0     0.019399 -0.812776  0.773442    -0.003651   \n",
       "\n",
       "   eem2015hm_1  eem2015hn_1  eem2015ba_1  eem2015bm_1  eem2015bn_1  atom_1  \\\n",
       "0    -0.813021    -0.784944    -0.067349    -0.806339    -0.851258       0   \n",
       "1     0.203254     0.196235     0.016837     0.201584     0.212813       1   \n",
       "\n",
       "        x_1       y_1       z_1         fc  type_0      dist    dist_x  \\\n",
       "0 -0.012698  1.085804  0.008001  83.534069       0  1.091953  0.000220   \n",
       "1  1.011731  1.463751  0.000277 -11.692044       1  1.783120  1.019253   \n",
       "\n",
       "     dist_y    dist_z  molecule_couples  molecule_dist_mean  \\\n",
       "0  1.192105  0.000036                10            1.506668   \n",
       "1  2.160261  0.000003                10            1.506668   \n",
       "\n",
       "   molecule_dist_min  molecule_dist_max  atom_0_couples_count  \\\n",
       "0           1.091946           1.783158                     4   \n",
       "1           1.091946           1.783158                     4   \n",
       "\n",
       "   atom_1_couples_count  molecule_atom_index_0_x_1_std  \\\n",
       "0                     4                       0.727907   \n",
       "1                     1                       0.727907   \n",
       "\n",
       "   molecule_atom_index_0_y_1_mean  molecule_atom_index_0_y_1_mean_diff  \\\n",
       "0                        1.358754                             0.272949   \n",
       "1                        1.358754                            -0.104998   \n",
       "\n",
       "   molecule_atom_index_0_y_1_mean_div  molecule_atom_index_0_y_1_max  \\\n",
       "0                            1.251380                       1.463751   \n",
       "1                            0.928268                       1.463751   \n",
       "\n",
       "   molecule_atom_index_0_y_1_max_diff  molecule_atom_index_0_y_1_std  \\\n",
       "0                            0.377947                       0.182278   \n",
       "1                            0.000000                       0.182278   \n",
       "\n",
       "   molecule_atom_index_0_z_1_std  molecule_atom_index_0_dist_mean  \\\n",
       "0                       0.727957                         1.610344   \n",
       "1                       0.727957                         1.610344   \n",
       "\n",
       "   molecule_atom_index_0_dist_mean_diff  molecule_atom_index_0_dist_mean_div  \\\n",
       "0                              0.518391                             1.474738   \n",
       "1                             -0.172776                             0.903105   \n",
       "\n",
       "   molecule_atom_index_0_dist_max  molecule_atom_index_0_dist_max_diff  \\\n",
       "0                        1.783157                             0.691204   \n",
       "1                        1.783157                             0.000037   \n",
       "\n",
       "   molecule_atom_index_0_dist_max_div  molecule_atom_index_0_dist_min  \\\n",
       "0                            1.632998                        1.091953   \n",
       "1                            1.000021                        1.091953   \n",
       "\n",
       "   molecule_atom_index_0_dist_min_diff  molecule_atom_index_0_dist_min_div  \\\n",
       "0                             0.000000                            1.000000   \n",
       "1                            -0.691167                            0.612383   \n",
       "\n",
       "   molecule_atom_index_0_dist_std  molecule_atom_index_0_dist_std_diff  \\\n",
       "0                        0.345594                            -0.746359   \n",
       "1                        0.345594                            -1.437526   \n",
       "\n",
       "   molecule_atom_index_0_dist_std_div  molecule_atom_index_1_dist_mean  \\\n",
       "0                            0.316492                          1.09195   \n",
       "1                            0.193814                          1.78312   \n",
       "\n",
       "   molecule_atom_index_1_dist_mean_diff  molecule_atom_index_1_dist_mean_div  \\\n",
       "0                             -0.000003                             0.999997   \n",
       "1                              0.000000                             1.000000   \n",
       "\n",
       "   molecule_atom_index_1_dist_max  molecule_atom_index_1_dist_max_diff  \\\n",
       "0                        1.091953                                  0.0   \n",
       "1                        1.783120                                  0.0   \n",
       "\n",
       "   molecule_atom_index_1_dist_max_div  molecule_atom_index_1_dist_min  \\\n",
       "0                                 1.0                        1.091946   \n",
       "1                                 1.0                        1.783120   \n",
       "\n",
       "   molecule_atom_index_1_dist_min_diff  molecule_atom_index_1_dist_min_div  \\\n",
       "0                            -0.000007                            0.999994   \n",
       "1                             0.000000                            1.000000   \n",
       "\n",
       "   molecule_atom_index_1_dist_std  molecule_atom_index_1_dist_std_diff  \\\n",
       "0                        0.000003                             -1.09195   \n",
       "1                             NaN                                  NaN   \n",
       "\n",
       "   molecule_atom_index_1_dist_std_div  molecule_atom_1_dist_mean  \\\n",
       "0                            0.000003                   1.091950   \n",
       "1                                 NaN                   1.783146   \n",
       "\n",
       "   molecule_atom_1_dist_min  molecule_atom_1_dist_min_diff  \\\n",
       "0                  1.091946                      -0.000007   \n",
       "1                  1.783120                       0.000000   \n",
       "\n",
       "   molecule_atom_1_dist_min_div  molecule_atom_1_dist_std  \\\n",
       "0                      0.999994                  0.000003   \n",
       "1                      1.000000                  0.000014   \n",
       "\n",
       "   molecule_atom_1_dist_std_diff  molecule_type_0_dist_std  \\\n",
       "0                      -1.091950                  0.000003   \n",
       "1                      -1.783106                  0.000014   \n",
       "\n",
       "   molecule_type_0_dist_std_diff  molecule_type_dist_mean  \\\n",
       "0                      -1.091950                 1.091950   \n",
       "1                      -1.783106                 1.783146   \n",
       "\n",
       "   molecule_type_dist_mean_diff  molecule_type_dist_mean_div  \\\n",
       "0                     -0.000003                     0.999997   \n",
       "1                      0.000027                     1.000015   \n",
       "\n",
       "   molecule_type_dist_max  molecule_type_dist_min  molecule_type_dist_std  \\\n",
       "0                1.091953                1.091946                0.000003   \n",
       "1                1.783158                1.783120                0.000014   \n",
       "\n",
       "   molecule_type_dist_std_diff  molecule_type_fc_max  molecule_type_fc_min  \\\n",
       "0                    -1.091950             87.113102             83.162207   \n",
       "1                    -1.783106            -10.558171            -11.692044   \n",
       "\n",
       "   molecule_type_fc_std  molecule_type_fc_std_diff  \\\n",
       "0              1.799476                 -81.734593   \n",
       "1              0.452166                  12.144210   \n",
       "\n",
       "   molecule_atom_index_0_fc_mean  molecule_atom_index_0_fc_mean_diff  \\\n",
       "0                      12.402786                          -71.131284   \n",
       "1                      12.402786                           24.094830   \n",
       "\n",
       "   molecule_atom_index_0_fc_mean_div  molecule_atom_index_0_fc_max  \\\n",
       "0                          11.358351                     83.534069   \n",
       "1                           6.955666                     83.534069   \n",
       "\n",
       "   molecule_atom_index_0_fc_max_diff  molecule_atom_index_0_fc_max_div  \\\n",
       "0                           0.000000                          1.000000   \n",
       "1                          95.226114                         -7.144522   \n",
       "\n",
       "   molecule_atom_index_0_fc_min  molecule_atom_index_0_fc_min_diff  \\\n",
       "0                    -11.692044                         -95.226114   \n",
       "1                    -11.692044                           0.000000   \n",
       "\n",
       "   molecule_atom_index_0_fc_min_div  molecule_atom_index_0_fc_std  \\\n",
       "0                         -0.139967                     47.422338   \n",
       "1                          1.000000                     47.422338   \n",
       "\n",
       "   molecule_atom_index_0_fc_std_diff  molecule_atom_index_0_fc_std_div  \\\n",
       "0                         -36.111731                          0.567701   \n",
       "1                          59.114383                         -4.055949   \n",
       "\n",
       "   molecule_atom_index_1_fc_mean  molecule_atom_index_1_fc_mean_diff  \\\n",
       "0                      84.475574                            0.941505   \n",
       "1                     -11.692044                            0.000000   \n",
       "\n",
       "   molecule_atom_index_1_fc_mean_div  molecule_atom_index_1_fc_max  \\\n",
       "0                           1.011271                     87.113102   \n",
       "1                           1.000000                    -11.692044   \n",
       "\n",
       "   molecule_atom_index_1_fc_max_diff  molecule_atom_index_1_fc_max_div  \\\n",
       "0                           3.579033                          1.042845   \n",
       "1                           0.000000                          1.000000   \n",
       "\n",
       "   molecule_atom_index_1_fc_min  molecule_atom_index_1_fc_min_diff  \\\n",
       "0                     83.162207                          -0.371863   \n",
       "1                    -11.692044                           0.000000   \n",
       "\n",
       "   molecule_atom_index_1_fc_min_div  molecule_atom_index_1_fc_std  \\\n",
       "0                          0.995548                      1.799476   \n",
       "1                          1.000000                           NaN   \n",
       "\n",
       "   molecule_atom_index_1_fc_std_diff  molecule_atom_index_1_fc_std_div  \\\n",
       "0                         -81.734593                          0.021542   \n",
       "1                                NaN                               NaN   \n",
       "\n",
       "   atom_index_closest_0  x_closest_0  y_closest_0  z_closest_0  \\\n",
       "0                     0    -0.012698     1.085804     0.008001   \n",
       "1                     0    -0.012698     1.085804     0.008001   \n",
       "\n",
       "   atom_index_closest_1  x_closest_1  y_closest_1  z_closest_1  distance_0  \\\n",
       "0                     3    -0.540815     1.447527    -0.876644    1.091953   \n",
       "1                     0    -0.012698     1.085804     0.008001    1.091953   \n",
       "\n",
       "   distance_1   cos_0_1     cos_0     cos_1  \n",
       "0    1.091946  0.333335 -1.000000 -0.333335  \n",
       "1    1.091952 -0.333287 -0.816483  0.816482  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'molecule_name', 'atom_index_1', 'atom_index_0', 'atom_2',\n",
      "       'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7',\n",
      "       ...\n",
      "       'z_closest_0', 'atom_index_closest_1', 'x_closest_1', 'y_closest_1',\n",
      "       'z_closest_1', 'distance_0', 'distance_1', 'cos_0_1', 'cos_0', 'cos_1'],\n",
      "      dtype='object', length=175)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 5521.85 Mb (5.3% reduction)\n",
      "Mem. usage decreased to 2989.23 Mb (5.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "y = train['scalar_coupling_constant']\n",
    "train = train.drop(['id', 'molecule_name', 'atom_0', 'scalar_coupling_constant'], axis=1)\n",
    "test  =  test.drop(['id', 'molecule_name', 'atom_0'], axis=1)\n",
    "train = reduce_mem_usage(train)\n",
    "test  = reduce_mem_usage(test)\n",
    "\n",
    "X = train.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "assert len(X.columns) == len(X_test.columns), f'X と X_test のサイズが違います X: {len(X.columns)}, X_test: {len(X_test.columns)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test, full_train, full_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "                                                  y,\n",
    "                                                  test_size = 0.30, \n",
    "                                                  random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define searched space\n",
    "hyper_space = {'objective': 'regression',\n",
    "               'metric':'mae',\n",
    "               'boosting':'gbdt',\n",
    "               'max_depth':  hp.choice('max_depth', [5, 8, 10, 15]),\n",
    "               'num_leaves': hp.choice('num_leaves', [50, 100, 250]),\n",
    "               'subsample': hp.choice('subsample', [.3, .5, .7, 1]),\n",
    "               'subsample_freq': 1,\n",
    "               'colsample_bytree': hp.choice('colsample_bytree', [ .6, .8, 1]),\n",
    "               'learning_rate': hp.choice('learning_rate', [0.01, .1, .3]),\n",
    "               'reg_alpha': hp.choice('reg_alpha', [.1, .2, .4, .6]),\n",
    "               'reg_lambda':  hp.choice('reg_lambda', [.1, .2, .4, .6]),               \n",
    "               'min_child_samples': hp.choice('min_child_samples', [20, 45, 70, 100]),\n",
    "               'verbosity': -1,\n",
    "               'bagging_seed': 11,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "- Training of type 0\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 1.41815\tvalid_1's l1: 1.42102\n",
      "cv_score:0.3513751747529856                         \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 1.41815\tvalid_1's l1: 1.42102\n",
      "cv_score:0.3513751747529856                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 1.36537\tvalid_1's l1: 1.3769\n",
      "cv_score:0.3198347325559636                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.86875\tvalid_1's l1: 0.965578\n",
      "cv_score:-0.03502789706371517                                                \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.881679\tvalid_1's l1: 0.974839\n",
      "cv_score:-0.02548306128258474                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.594007\tvalid_1's l1: 0.843648\n",
      "cv_score:-0.17001953594862781                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.948518\tvalid_1's l1: 1.02364\n",
      "cv_score:0.023364570848203297                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.575691\tvalid_1's l1: 0.841212\n",
      "cv_score:-0.17291211422645755                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.987277\tvalid_1's l1: 1.05143\n",
      "cv_score:0.05014683673186222                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.575691\tvalid_1's l1: 0.841212\n",
      "cv_score:-0.1729117796797933                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.528239\tvalid_1's l1: 0.900878\n",
      "cv_score:-0.104384913391696                                                     \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.748194\tvalid_1's l1: 0.913472\n",
      "cv_score:-0.090502088167831                                                     \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.932453\tvalid_1's l1: 1.00323\n",
      "cv_score:0.0032232511657716177                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.681327\tvalid_1's l1: 1.01111\n",
      "cv_score:0.011047279310466201                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.645299\tvalid_1's l1: 0.875531\n",
      "cv_score:-0.13292468989720446                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.839088\tvalid_1's l1: 0.954658\n",
      "cv_score:-0.04640254923121762                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 1.41812\tvalid_1's l1: 1.42132\n",
      "cv_score:0.3515833427729894                                                     \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.575691\tvalid_1's l1: 0.841212\n",
      "cv_score:-0.1729117796797933                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.575691\tvalid_1's l1: 0.841212\n",
      "cv_score:-0.1729117796797933                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                  \n",
      "Did not meet early stopping. Best iteration is:                                 \n",
      "[450]\ttraining's l1: 0.575691\tvalid_1's l1: 0.841212\n",
      "cv_score:-0.1729117796797933                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [06:54<00:00, 23.04s/it, best loss: -0.17291211422645755]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 1, 'learning_rate': 0.3, 'max_depth': 8, 'metric': 'mae', 'min_child_samples': 70, 'num_leaves': 250, 'objective': 'regression', 'reg_alpha': 0.1, 'reg_lambda': 0.6, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 1\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.283288\tvalid_1's l1: 0.457103\n",
      "cv_score:-0.7828461439184334                        \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.283288\tvalid_1's l1: 0.457103\n",
      "cv_score:-0.7828461439184334                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.32337\tvalid_1's l1: 0.461289\n",
      "cv_score:-0.7737315926565913                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.648185\tvalid_1's l1: 0.666299\n",
      "cv_score:-0.4060169345942856                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Early stopping, best iteration is:                                            \n",
      "[97]\ttraining's l1: 0.372854\tvalid_1's l1: 0.586488\n",
      "cv_score:-0.5336028228669758                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.138415\tvalid_1's l1: 0.411269\n",
      "cv_score:-0.888507836611627                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.420649\tvalid_1's l1: 0.537476\n",
      "cv_score:-0.6208713122216886                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.100311\tvalid_1's l1: 0.43686\n",
      "cv_score:-0.8281425355207783                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.138415\tvalid_1's l1: 0.411269\n",
      "cv_score:-0.888507836611627                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.138415\tvalid_1's l1: 0.411269\n",
      "cv_score:-0.888507836611627                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.337206\tvalid_1's l1: 0.474061\n",
      "cv_score:-0.746419381170911                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.221896\tvalid_1's l1: 0.465551\n",
      "cv_score:-0.7645340064885473                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.583379\tvalid_1's l1: 0.623493\n",
      "cv_score:-0.47241712737304986                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.339116\tvalid_1's l1: 0.47587\n",
      "cv_score:-0.7426098074136215                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.218534\tvalid_1's l1: 0.461235\n",
      "cv_score:-0.7738486513075881                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.140091\tvalid_1's l1: 0.407665\n",
      "cv_score:-0.897309466063438                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.421827\tvalid_1's l1: 0.538463\n",
      "cv_score:-0.6190363590798295                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.140091\tvalid_1's l1: 0.407665\n",
      "cv_score:-0.897309466063438                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.140091\tvalid_1's l1: 0.407665\n",
      "cv_score:-0.897309466063438                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.140091\tvalid_1's l1: 0.407665\n",
      "cv_score:-0.897309466063438                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [01:59<00:00,  7.70s/it, best loss: -0.897309466063438]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'metric': 'mae', 'min_child_samples': 70, 'num_leaves': 100, 'objective': 'regression', 'reg_alpha': 0.4, 'reg_lambda': 0.4, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 2\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.224811\tvalid_1's l1: 0.335194\n",
      "cv_score:-1.0930466589703876                        \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.224811\tvalid_1's l1: 0.335194\n",
      "cv_score:-1.093046658970395                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.570817\tvalid_1's l1: 0.575751\n",
      "cv_score:-0.552080870950401                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.373459\tvalid_1's l1: 0.405997\n",
      "cv_score:-0.9014094644550334                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.244346\tvalid_1's l1: 0.330972\n",
      "cv_score:-1.105721176531606                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.244346\tvalid_1's l1: 0.330972\n",
      "cv_score:-1.105721176531606                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.595854\tvalid_1's l1: 0.599965\n",
      "cv_score:-0.5108842058618941                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.430778\tvalid_1's l1: 0.449284\n",
      "cv_score:-0.8001009427438334                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.282087\tvalid_1's l1: 0.344776\n",
      "cv_score:-1.0648594807532237                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.244346\tvalid_1's l1: 0.330972\n",
      "cv_score:-1.1057205602643434                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.571276\tvalid_1's l1: 0.57636\n",
      "cv_score:-0.5510234780218944                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.414699\tvalid_1's l1: 0.435991\n",
      "cv_score:-0.830134267913381                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.375316\tvalid_1's l1: 0.406124\n",
      "cv_score:-0.901095561582867                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.430923\tvalid_1's l1: 0.451515\n",
      "cv_score:-0.7951471783678248                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.217664\tvalid_1's l1: 0.354679\n",
      "cv_score:-1.0365422995517959                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.555185\tvalid_1's l1: 0.562741\n",
      "cv_score:-0.5749354165221896                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.421814\tvalid_1's l1: 0.439778\n",
      "cv_score:-0.82148452414555                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.244346\tvalid_1's l1: 0.330972\n",
      "cv_score:-1.1057211850307254                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.244346\tvalid_1's l1: 0.330972\n",
      "cv_score:-1.1057205602643434                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.244346\tvalid_1's l1: 0.330972\n",
      "cv_score:-1.105721176531606                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [10:04<00:00, 33.70s/it, best loss: -1.1057211850307254]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 8, 'metric': 'mae', 'min_child_samples': 45, 'num_leaves': 250, 'objective': 'regression', 'reg_alpha': 0.6, 'reg_lambda': 0.4, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 3\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.167737\tvalid_1's l1: 0.205542\n",
      "cv_score:-1.5821049837164622                        \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.167737\tvalid_1's l1: 0.205542\n",
      "cv_score:-1.5821049837159742                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.278067\tvalid_1's l1: 0.285928\n",
      "cv_score:-1.252013986010223                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.187764\tvalid_1's l1: 0.216374\n",
      "cv_score:-1.5307473589077707                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.200182\tvalid_1's l1: 0.226978\n",
      "cv_score:-1.4829008395741243                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.186484\tvalid_1's l1: 0.219427\n",
      "cv_score:-1.5167339312371748                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.167737\tvalid_1's l1: 0.205542\n",
      "cv_score:-1.5821049837164622                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.303808\tvalid_1's l1: 0.305343\n",
      "cv_score:-1.1863190291349746                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.196887\tvalid_1's l1: 0.222994\n",
      "cv_score:-1.5006087728658655                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.169091\tvalid_1's l1: 0.207242\n",
      "cv_score:-1.573869767384769                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.121681\tvalid_1's l1: 0.197518\n",
      "cv_score:-1.621927648964721                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Early stopping, best iteration is:                                            \n",
      "[213]\ttraining's l1: 0.139654\tvalid_1's l1: 0.246939\n",
      "cv_score:-1.3986139716332446                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.25462\tvalid_1's l1: 0.269297\n",
      "cv_score:-1.3119412590256885                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.121681\tvalid_1's l1: 0.197518\n",
      "cv_score:-1.621927648964721                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.182463\tvalid_1's l1: 0.240975\n",
      "cv_score:-1.4230618666532402                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.117861\tvalid_1's l1: 0.195519\n",
      "cv_score:-1.6320960709035925                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.257392\tvalid_1's l1: 0.270886\n",
      "cv_score:-1.3060580345365576                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.117861\tvalid_1's l1: 0.195519\n",
      "cv_score:-1.6320960709035925                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.117861\tvalid_1's l1: 0.195519\n",
      "cv_score:-1.6320960709035925                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.117861\tvalid_1's l1: 0.195519\n",
      "cv_score:-1.6320960709035925                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [06:02<00:00, 24.91s/it, best loss: -1.6320960709035925]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 15, 'metric': 'mae', 'min_child_samples': 20, 'num_leaves': 250, 'objective': 'regression', 'reg_alpha': 0.2, 'reg_lambda': 0.4, 'subsample': 0.3, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 4\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.144262\tvalid_1's l1: 0.190685\n",
      "cv_score:-1.6571346278704264                        \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.144262\tvalid_1's l1: 0.190685\n",
      "cv_score:-1.6571346278700134                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.157211\tvalid_1's l1: 0.204078\n",
      "cv_score:-1.589253347480696                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.09562\tvalid_1's l1: 0.187621\n",
      "cv_score:-1.6733303037592502                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0476851\tvalid_1's l1: 0.175272\n",
      "cv_score:-1.7414186567282606                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.228793\tvalid_1's l1: 0.243247\n",
      "cv_score:-1.4136786923028724                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0896245\tvalid_1's l1: 0.202463\n",
      "cv_score:-1.5971996507598032                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.13031\tvalid_1's l1: 0.189351\n",
      "cv_score:-1.664153131491116                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0476851\tvalid_1's l1: 0.175272\n",
      "cv_score:-1.7414186567282606                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.190897\tvalid_1's l1: 0.219635\n",
      "cv_score:-1.5157867517225168                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.150039\tvalid_1's l1: 0.209953\n",
      "cv_score:-1.5608737418526875                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Early stopping, best iteration is:                                             \n",
      "[231]\ttraining's l1: 0.176983\tvalid_1's l1: 0.248246\n",
      "cv_score:-1.393334726003922                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.191199\tvalid_1's l1: 0.219818\n",
      "cv_score:-1.5149559684194718                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Early stopping, best iteration is:                                             \n",
      "[147]\ttraining's l1: 0.159865\tvalid_1's l1: 0.239168\n",
      "cv_score:-1.4305879541126325                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.181337\tvalid_1's l1: 0.227427\n",
      "cv_score:-1.4809253404306184                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.140306\tvalid_1's l1: 0.188336\n",
      "cv_score:-1.6695263601158246                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.192871\tvalid_1's l1: 0.221038\n",
      "cv_score:-1.5094190187272525                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0476851\tvalid_1's l1: 0.175272\n",
      "cv_score:-1.7414186567259375                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0476851\tvalid_1's l1: 0.175272\n",
      "cv_score:-1.7414186567283596                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0476851\tvalid_1's l1: 0.175272\n",
      "cv_score:-1.7414186567282606                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [02:30<00:00,  8.47s/it, best loss: -1.7414186567283596]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 15, 'metric': 'mae', 'min_child_samples': 70, 'num_leaves': 100, 'objective': 'regression', 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 5\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.498588\tvalid_1's l1: 0.499894\n",
      "cv_score:-0.693359387921796                         \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.498588\tvalid_1's l1: 0.499894\n",
      "cv_score:-0.6933593879217957                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.335489\tvalid_1's l1: 0.379361\n",
      "cv_score:-0.9692662310582691                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.416637\tvalid_1's l1: 0.42913\n",
      "cv_score:-0.8459964675618605                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.305341\tvalid_1's l1: 0.350806\n",
      "cv_score:-1.047522350118236                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.339868\tvalid_1's l1: 0.37329\n",
      "cv_score:-0.9853987078766547                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.305837\tvalid_1's l1: 0.353571\n",
      "cv_score:-1.0396710614114475                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.339868\tvalid_1's l1: 0.37329\n",
      "cv_score:-0.9853987078766547                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.305341\tvalid_1's l1: 0.350806\n",
      "cv_score:-1.0475227781785657                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.293129\tvalid_1's l1: 0.339076\n",
      "cv_score:-1.0815306340163655                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.292481\tvalid_1's l1: 0.342282\n",
      "cv_score:-1.072119879702789                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.506454\tvalid_1's l1: 0.507253\n",
      "cv_score:-0.6787449705165998                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.348988\tvalid_1's l1: 0.378361\n",
      "cv_score:-0.971905201174621                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.398269\tvalid_1's l1: 0.411273\n",
      "cv_score:-0.8884988581082328                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.37564\tvalid_1's l1: 0.396522\n",
      "cv_score:-0.9250230954256795                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.343742\tvalid_1's l1: 0.370071\n",
      "cv_score:-0.9940606312382573                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.473881\tvalid_1's l1: 0.479305\n",
      "cv_score:-0.7354178901778613                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.292481\tvalid_1's l1: 0.342282\n",
      "cv_score:-1.072119879702789                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.292481\tvalid_1's l1: 0.342282\n",
      "cv_score:-1.072119879702789                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.291573\tvalid_1's l1: 0.341326\n",
      "cv_score:-1.0749183167909497                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [13:14<00:00, 45.92s/it, best loss: -1.0815306340163655]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 1, 'learning_rate': 0.3, 'max_depth': 8, 'metric': 'mae', 'min_child_samples': 20, 'num_leaves': 100, 'objective': 'regression', 'reg_alpha': 0.6, 'reg_lambda': 0.2, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 6\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.0833021\tvalid_1's l1: 0.181228\n",
      "cv_score:-1.7079985075161637                        \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0833021\tvalid_1's l1: 0.181229\n",
      "cv_score:-1.7079955956780726                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.239696\tvalid_1's l1: 0.247381\n",
      "cv_score:-1.3968258755236023                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.142758\tvalid_1's l1: 0.195674\n",
      "cv_score:-1.6313036673193257                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.216914\tvalid_1's l1: 0.232666\n",
      "cv_score:-1.4581529694982804                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.214547\tvalid_1's l1: 0.231141\n",
      "cv_score:-1.4647273911034961                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.166377\tvalid_1's l1: 0.201027\n",
      "cv_score:-1.6043165189420714                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.257686\tvalid_1's l1: 0.260136\n",
      "cv_score:-1.3465519292191204                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.159519\tvalid_1's l1: 0.209058\n",
      "cv_score:-1.5651420405855117                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0844208\tvalid_1's l1: 0.179364\n",
      "cv_score:-1.7183388206478127                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.208868\tvalid_1's l1: 0.224883\n",
      "cv_score:-1.4921763855492172                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.267624\tvalid_1's l1: 0.268575\n",
      "cv_score:-1.3146256724354413                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.157372\tvalid_1's l1: 0.205227\n",
      "cv_score:-1.5836392375787938                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.212938\tvalid_1's l1: 0.230874\n",
      "cv_score:-1.4658823821508664                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.267545\tvalid_1's l1: 0.268372\n",
      "cv_score:-1.3153808200615522                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.137027\tvalid_1's l1: 0.192311\n",
      "cv_score:-1.6486435070700243                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.176965\tvalid_1's l1: 0.205166\n",
      "cv_score:-1.5839361009818234                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0833021\tvalid_1's l1: 0.181228\n",
      "cv_score:-1.7079985075150412                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0831804\tvalid_1's l1: 0.179472\n",
      "cv_score:-1.717734918266574                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0814069\tvalid_1's l1: 0.179775\n",
      "cv_score:-1.7160500988510703                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [06:21<00:00, 21.75s/it, best loss: -1.7183388206478127]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 0.6, 'learning_rate': 0.3, 'max_depth': 15, 'metric': 'mae', 'min_child_samples': 100, 'num_leaves': 250, 'objective': 'regression', 'reg_alpha': 0.2, 'reg_lambda': 0.4, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n",
      "********************************************************************************\n",
      "- Training of type 7\n",
      "********************************************************************************\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:     \n",
      "[450]\ttraining's l1: 0.0837347\tvalid_1's l1: 0.132454\n",
      "cv_score:-2.021520326194236                         \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.0837347\tvalid_1's l1: 0.132454\n",
      "cv_score:-2.0215203164618885                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.0897226\tvalid_1's l1: 0.135506\n",
      "cv_score:-1.9987403559605572                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.183824\tvalid_1's l1: 0.185337\n",
      "cv_score:-1.6855816046443501                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.0977512\tvalid_1's l1: 0.158958\n",
      "cv_score:-1.8391179656396481                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.110141\tvalid_1's l1: 0.151807\n",
      "cv_score:-1.8851434098773139                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.165608\tvalid_1's l1: 0.173638\n",
      "cv_score:-1.750784773259381                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.0165094\tvalid_1's l1: 0.147661\n",
      "cv_score:-1.9128367314106935                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.12372\tvalid_1's l1: 0.15056\n",
      "cv_score:-1.8933928266457436                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.               \n",
      "Did not meet early stopping. Best iteration is:                              \n",
      "[450]\ttraining's l1: 0.14369\tvalid_1's l1: 0.158823\n",
      "cv_score:-1.8399618194356169                                                 \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.177584\tvalid_1's l1: 0.180507\n",
      "cv_score:-1.7119868150291793                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0138162\tvalid_1's l1: 0.131033\n",
      "cv_score:-2.0323080944697223                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.145532\tvalid_1's l1: 0.170703\n",
      "cv_score:-1.767832979189042                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0558393\tvalid_1's l1: 0.153547\n",
      "cv_score:-1.8737484625612084                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0376378\tvalid_1's l1: 0.139126\n",
      "cv_score:-1.9723716950009358                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0161126\tvalid_1's l1: 0.136886\n",
      "cv_score:-1.9886087769331162                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0138162\tvalid_1's l1: 0.131033\n",
      "cv_score:-2.0323080944697223                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                                \n",
      "[450]\ttraining's l1: 0.0138162\tvalid_1's l1: 0.131033\n",
      "cv_score:-2.032308094470347                                                    \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                 \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0138162\tvalid_1's l1: 0.131033\n",
      "cv_score:-2.032308094470347                                                   \n",
      "--------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.                \n",
      "Did not meet early stopping. Best iteration is:                               \n",
      "[450]\ttraining's l1: 0.0138162\tvalid_1's l1: 0.131033\n",
      "cv_score:-2.0323080944697223                                                  \n",
      "--------------------------------------------------------------------------------\n",
      "100%|██████████| 20/20 [03:41<00:00, 16.81s/it, best loss: -2.032308094470347]\n",
      "BEST PARAMETERS: {'bagging_seed': 11, 'boosting': 'gbdt', 'colsample_bytree': 1, 'learning_rate': 0.3, 'max_depth': 15, 'metric': 'mae', 'min_child_samples': 45, 'num_leaves': 250, 'objective': 'regression', 'reg_alpha': 0.2, 'reg_lambda': 0.2, 'subsample': 1, 'subsample_freq': 1, 'verbosity': -1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# type ごとの学習 \n",
    "\n",
    "# feature_importance  = pd.DataFrame()\n",
    "# X_short      = pd.DataFrame({'ind': list(X.index),      'type': X['type'].values,      'oof': [0] * len(X), 'target': y_fc})\n",
    "# X_short_test = pd.DataFrame({'ind': list(X_test.index), 'type': X_test['type'].values, 'prediction': [0] * len(X_test)})\n",
    "best_params_list = []\n",
    "for t in sorted(X_train['type'].unique()):\n",
    "    print('*'*80)\n",
    "    print(f'- Training of type {t}')\n",
    "    print('*'*80)\n",
    "    X_t_train = X_train.loc[X_train['type'] == t]\n",
    "    X_t_valid = X_valid.loc[X_valid['type'] == t]\n",
    "    y_t_train = y_train[X_train['type'] == t]\n",
    "    y_t_valid = y_valid[X_valid['type'] == t]\n",
    "    \n",
    "    \n",
    "    # evaluate_metric\n",
    "    def evaluate_metric(params):\n",
    "    #     model_lgb = lgb.train(params, lgtrain, 500, \n",
    "    #                           valid_sets=[lgtrain, lgval], early_stopping_rounds=20, \n",
    "    #                           verbose_eval=500)\n",
    "    #     model_lgb = lgb.train(para)\n",
    "        model_lgb = lgb.LGBMRegressor(**params, n_jobs=N_JOBS, n_estimators=450) \n",
    "        model_lgb.fit(X_t_train, y_t_train,\n",
    "                  eval_set=[(X_t_train, y_t_train), (X_t_valid, y_t_valid)],\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=100)\n",
    "\n",
    "        pred = model_lgb.predict(X_t_valid)\n",
    "\n",
    "        _X_t_valid = X_t_valid.copy()\n",
    "        _X_t_valid['scalar_coupling_constant'] = y_t_valid\n",
    "        cv_score = kaggle_metric(_X_t_valid, pred)\n",
    "        _X_t_valid = _X_t_valid.drop(['scalar_coupling_constant'], axis=1)\n",
    "\n",
    "#         print(f'mae(valid): {mean_absolute_error(y_t_valid, pred)}')\n",
    "        print(f'cv_score:{cv_score}')\n",
    "        print('-'*80)\n",
    "        print('\\n')\n",
    "\n",
    "        return {\n",
    "            'loss': cv_score,\n",
    "            'status': STATUS_OK,\n",
    "            'stats_running': STATUS_RUNNING\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # hyperopt\n",
    "    # Trail\n",
    "    trials = Trials()\n",
    "\n",
    "    # Set algoritm parameters\n",
    "    algo = partial(tpe.suggest, \n",
    "                   n_startup_jobs=-1)\n",
    "\n",
    "    # Seting the number of Evals\n",
    "    MAX_EVALS= 20\n",
    "\n",
    "    # Fit Tree Parzen Estimator\n",
    "    best_vals = fmin(evaluate_metric, space=hyper_space, verbose=1,\n",
    "                     algo=algo, max_evals=MAX_EVALS, trials=trials)\n",
    "\n",
    "    # Print best parameters\n",
    "    best_params = space_eval(hyper_space, best_vals)\n",
    "    best_params_list.append(best_params)\n",
    "    print(\"BEST PARAMETERS: \" + str(best_params))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 1,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 8,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 70,\n",
       "  'num_leaves': 250,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.6,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 0.8,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 15,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 70,\n",
       "  'num_leaves': 100,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.4,\n",
       "  'reg_lambda': 0.4,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 0.8,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 8,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 45,\n",
       "  'num_leaves': 250,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.6,\n",
       "  'reg_lambda': 0.4,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 1,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 15,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 20,\n",
       "  'num_leaves': 250,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.2,\n",
       "  'reg_lambda': 0.4,\n",
       "  'subsample': 0.3,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 0.8,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 15,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 70,\n",
       "  'num_leaves': 100,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 0.2,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 1,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 8,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 20,\n",
       "  'num_leaves': 100,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.6,\n",
       "  'reg_lambda': 0.2,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 0.6,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 15,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 100,\n",
       "  'num_leaves': 250,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.2,\n",
       "  'reg_lambda': 0.4,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1},\n",
       " {'bagging_seed': 11,\n",
       "  'boosting': 'gbdt',\n",
       "  'colsample_bytree': 1,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 15,\n",
       "  'metric': 'mae',\n",
       "  'min_child_samples': 45,\n",
       "  'num_leaves': 250,\n",
       "  'objective': 'regression',\n",
       "  'reg_alpha': 0.2,\n",
       "  'reg_lambda': 0.2,\n",
       "  'subsample': 1,\n",
       "  'subsample_freq': 1,\n",
       "  'verbosity': -1}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_params_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[{'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 70,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.1,\n",
    "  'reg_lambda': 0.6,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.8,\n",
    "  'learning_rate': 0.1,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 70,\n",
    "  'num_leaves': 100,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.4,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.8,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 45,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.6,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.1,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 20,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.2,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 0.3,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.8,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 70,\n",
    "  'num_leaves': 100,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.1,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 20,\n",
    "  'num_leaves': 100,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.6,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.6,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 100,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.2,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 45,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.2,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

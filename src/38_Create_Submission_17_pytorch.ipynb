{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- distance とその統計量  \n",
    "- cos features  \n",
    "- dist_interact  \n",
    "- openbabelcharge 特徴量(nb32)\n",
    "- fc\n",
    "- nb36 の特徴量を用いて、NNを使用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "import glob\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightgbm as lgb\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "nb = 38\n",
    "isSmallSet = False\n",
    "length = 2000\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/champs-scalar-coupling/scalar_coupling_contributions.csv',\n",
       " '../input/champs-scalar-coupling/magnetic_shielding_tensors.csv',\n",
       " '../input/champs-scalar-coupling/structures.csv',\n",
       " '../input/champs-scalar-coupling/test.csv',\n",
       " '../input/champs-scalar-coupling/dipole_moments.csv',\n",
       " '../input/champs-scalar-coupling/potential_energy.csv',\n",
       " '../input/champs-scalar-coupling/sample_submission.csv',\n",
       " '../input/champs-scalar-coupling/train.csv',\n",
       " '../input/champs-scalar-coupling/nb33_train_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_test_feature.csv',\n",
       " '../input/champs-scalar-coupling/train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/nb33_test_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/mulliken_charges.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_train_feature.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../input/champs-scalar-coupling/'\n",
    "glob.glob(file_path + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "path = file_path + 'train.csv'\n",
    "if isSmallSet:\n",
    "    train = pd.read_csv(path) [:length]\n",
    "else:\n",
    "    train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = file_path + 'test.csv'\n",
    "if isSmallSet:\n",
    "    test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure\n",
    "path = file_path + 'structures.csv'\n",
    "structures = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_train\n",
    "path = file_path + 'nb29_fc_train_feature.csv'\n",
    "if isSmallSet:\n",
    "    fc_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_test\n",
    "path = file_path + 'nb29_fc_test_feature.csv'\n",
    "if isSmallSet:\n",
    "    fc_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dist-interact\n",
    "path = file_path + 'nb33_train_dist-interaction.csv'\n",
    "if isSmallSet:\n",
    "    dist_interact_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    dist_interact_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dist-interact\n",
    "path = file_path + 'nb33_test_dist-interaction.csv'\n",
    "if isSmallSet:\n",
    "    dist_interact_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    dist_interact_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge train\n",
    "path = file_path + 'train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_train = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_train = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge test\n",
    "path = file_path + 'test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_test = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_test = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 2505542)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(fc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 4658147)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(fc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4658147 rows in train data.\n",
      "There are 2505542 rows in test data.\n",
      "There are 85003 distinct molecules in train data.\n",
      "There are 45772 distinct molecules in test data.\n",
      "There are 29 unique atoms.\n",
      "There are 8 unique types.\n"
     ]
    }
   ],
   "source": [
    "if isSmallSet:\n",
    "    print('using SmallSet !!')\n",
    "    print('-------------------')\n",
    "\n",
    "print(f'There are {train.shape[0]} rows in train data.')\n",
    "print(f'There are {test.shape[0]} rows in test data.')\n",
    "\n",
    "print(f\"There are {train['molecule_name'].nunique()} distinct molecules in train data.\")\n",
    "print(f\"There are {test['molecule_name'].nunique()} distinct molecules in test data.\")\n",
    "print(f\"There are {train['atom_index_0'].nunique()} unique atoms.\")\n",
    "print(f\"There are {train['type'].nunique()} unique types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## myFunc\n",
    "**metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_metric(df, preds):\n",
    "    df[\"prediction\"] = preds\n",
    "    maes = []\n",
    "    for t in df.type.unique():\n",
    "        y_true = df[df.type==t].scalar_coupling_constant.values\n",
    "        y_pred = df[df.type==t].prediction.values\n",
    "        mae = np.log(mean_absolute_error(y_true, y_pred))\n",
    "        maes.append(mae)\n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**momory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dist-interact**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dist_interact'] = dist_interact_train.values\n",
    "test['dist_interact'] = dist_interact_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**basic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# structure and ob_charges\n",
    "ob_charge = pd.concat([ob_charge_train, ob_charge_test])\n",
    "merge = pd.merge(ob_charge, structures, how='left',\n",
    "                  left_on  = ['molecule_name', 'atom_index'],\n",
    "                  right_on = ['molecule_name', 'atom_index'])\n",
    "for atom_idx in [0,1]:\n",
    "    train = map_atom_info(train, merge, atom_idx)\n",
    "    test  = map_atom_info(test,  merge, atom_idx)\n",
    "    \n",
    "    train = train.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}',\n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}',})\n",
    "    test = test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}', \n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}'})\n",
    "#     test  =  test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "#                                         'x': f'x_{atom_idx}',\n",
    "#                                         'y': f'y_{atom_idx}',\n",
    "#                                         'z': f'z_{atom_idx}'})\n",
    "\n",
    "# ob_charges\n",
    "# train = map_atom_info(train, ob_charge_train, 0)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  0)\n",
    "# train = map_atom_info(train, ob_charge_train, 1)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "for atom_idx in [0,1]:\n",
    "    train = map_atom_info(train, structures, atom_idx)\n",
    "    test  = map_atom_info(test, structures, atom_idx)\n",
    "    \n",
    "    train = train.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}'})\n",
    "    test  =  test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`type` の特徴量から、数字を抽出  \n",
    "例) 2JHC ---> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type0(df):\n",
    "    df['type_0'] = df['type'].apply(lambda x : x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(df):\n",
    "    df_p_0 = df[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df[['x_1', 'y_1', 'z_1']].values\n",
    "    \n",
    "    df['dist'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "    df['dist_x'] = (df['x_0'] - df['x_1']) ** 2\n",
    "    df['dist_y'] = (df['y_0'] - df['y_1']) ** 2\n",
    "    df['dist_z'] = (df['z_0'] - df['z_1']) ** 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "# train = distances(train)\n",
    "# test  = distances(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distance 統計量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "angle features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_closest(df):\n",
    "    df_temp=df.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"dist\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"dist\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance', 'dist'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                        'x_closest': f'x_closest_{atom_idx}',\n",
    "                                        'y_closest': f'y_closest_{atom_idx}',\n",
    "                                        'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "def add_cos_features(df):\n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"dist\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"dist\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"dist\"]\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add fc\n",
      "4658147 2505542\n",
      "type0\n",
      "4658147 2505542\n",
      "distances\n",
      "4658147 2505542\n",
      "create_featueres\n",
      "4658147 2505542\n",
      "create_closest\n",
      "4658147 2505542\n",
      "add_cos_features\n",
      "4658154 2505542\n",
      "CPU times: user 1min 38s, sys: 2min 17s, total: 3min 56s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('add fc')\n",
    "print(len(train), len(test))\n",
    "train['fc'] = fc_train.values\n",
    "test['fc']  = fc_test.values\n",
    "\n",
    "print('type0')\n",
    "print(len(train), len(test))\n",
    "train = create_type0(train)\n",
    "test  = create_type0(test)\n",
    "\n",
    "print('distances')\n",
    "print(len(train), len(test))\n",
    "train = distances(train)\n",
    "test  = distances(test)\n",
    "\n",
    "print('create_featueres')\n",
    "print(len(train), len(test))\n",
    "train = create_features(train)\n",
    "test  = create_features(test)\n",
    "\n",
    "print('create_closest')\n",
    "print(len(train), len(test))\n",
    "train = create_closest(train)\n",
    "test  = create_closest(test)\n",
    "\n",
    "print('add_cos_features')\n",
    "print(len(train), len(test))\n",
    "train = add_cos_features(train)\n",
    "test  = add_cos_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "カテゴリカル特徴量 と 数値特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='109' class='' max='109', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [109/109 00:34<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecule_atom_index_0_y_1_mean_div\n"
     ]
    }
   ],
   "source": [
    "# inf がある特徴量を削除\n",
    "df = train\n",
    "for feat in progress_bar(df.columns):\n",
    "    logi = (df[feat]==np.inf)\n",
    "    if sum(logi) >= 1:\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['molecule_atom_index_0_y_1_mean_div'], axis=1)\n",
    "test  =  test.drop(['molecule_atom_index_0_y_1_mean_div'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "atom_index_0\n",
      "atom_index_1\n",
      "molecule_couples\n",
      "atom_0_couples_count\n",
      "atom_1_couples_count\n",
      "atom_index_closest_0\n",
      "atom_index_closest_1\n"
     ]
    }
   ],
   "source": [
    "# int 型の列挙\n",
    "for feat in train.columns:\n",
    "    if train[feat].dtypes == np.dtype('int64'):\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリカル: ['atom_1', 'type_0', 'type']\n",
      "数値:        ['molecule_atom_index_0_dist_max', 'molecule_atom_index_1_dist_max', 'molecule_type_dist_mean_div', 'gasteiger_0', 'molecule_type_dist_mean', 'molecule_atom_index_1_dist_std', 'molecule_atom_index_1_dist_std_div', 'molecule_atom_1_dist_mean', 'y_0', 'molecule_atom_1_dist_std_diff', 'molecule_atom_index_0_dist_mean_diff', 'distance_1', 'x_closest_0', 'molecule_atom_index_0_dist_max_div', 'molecule_atom_index_1_dist_min_diff', 'molecule_atom_index_0_dist_mean_div', 'dist_interact', 'molecule_atom_1_dist_std', 'cos_1', 'y_1', 'molecule_atom_index_1_dist_mean_div', 'z_1', 'dist_y', 'mmff94_1', 'molecule_atom_index_1_dist_std_diff', 'molecule_dist_min', 'molecule_atom_index_0_dist_std_diff', 'y_closest_0', 'qeq_0', 'molecule_atom_index_1_dist_max_diff', 'molecule_atom_index_0_x_1_std', 'cos_0', 'molecule_atom_index_0_dist_min', 'x_1', 'molecule_atom_index_0_y_1_mean', 'qtpie_0', 'cos_0_1', 'molecule_type_dist_max', 'x_0', 'eem2015ba_0', 'eem2015hn_0', 'eem2015bm_1', 'molecule_type_dist_std_diff', 'molecule_atom_index_0_y_1_max', 'eem2015bm_0', 'qeq_1', 'molecule_atom_1_dist_min_div', 'dist', 'molecule_atom_index_0_y_1_max_diff', 'molecule_type_dist_min', 'distance_0', 'molecule_atom_index_0_z_1_std', 'eem2015ha_0', 'eem2015ba_1', 'x_closest_1', 'eem2015bn_0', 'molecule_atom_index_0_dist_min_diff', 'y_closest_1', 'atom_index_1', 'molecule_type_0_dist_std', 'z_0', 'molecule_atom_index_0_y_1_mean_diff', 'molecule_atom_index_1_dist_max_div', 'fc', 'z_closest_0', 'molecule_atom_1_dist_min', 'molecule_atom_index_0_dist_mean', 'eem2015hn_1', 'dist_x', 'molecule_atom_index_1_dist_mean', 'molecule_type_dist_std', 'atom_index_0', 'molecule_atom_index_1_dist_min_div', 'eem2015bn_1', 'eem2015hm_1', 'dist_z', 'molecule_atom_index_0_dist_min_div', 'molecule_atom_index_1_dist_mean_diff', 'z_closest_1', 'mmff94_0', 'molecule_couples', 'eem_0', 'molecule_atom_index_0_dist_max_diff', 'molecule_atom_index_0_dist_std_div', 'molecule_atom_index_0_dist_std', 'eem2015hm_0', 'molecule_atom_1_dist_min_diff', 'qtpie_1', 'molecule_atom_index_0_y_1_std', 'molecule_dist_max', 'gasteiger_1', 'molecule_dist_mean', 'molecule_type_0_dist_std_diff', 'eem_1', 'molecule_type_dist_mean_diff', 'eem2015ha_1', 'molecule_atom_index_1_dist_min']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['atom_1','type_0','type']\n",
    "num_cols = list(set(train.columns) - set(cat_cols) - set([\"scalar_coupling_constant\", 'molecule_name', 'id', 'atom_0',\n",
    "                                                          'atom_0_couples_count', 'atom_1_couples_count', 'atom_index_closest_0', 'atom_index_closest_1']))\n",
    "print(f'カテゴリカル: {cat_cols}')\n",
    "print(f'数値:        {num_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "LabelEncode\n",
    "- `atom_1` = {H, C, N}\n",
    "- `type_0` = {1, 2, 3}\n",
    "- `type`   = {2JHC, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['atom_1', 'type_0', 'type']:\n",
    "    if f in train.columns:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[num_cols] = train[num_cols].fillna(0)\n",
    "test[num_cols]  =  test[num_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling numerical columns\n"
     ]
    }
   ],
   "source": [
    "print('scaling numerical columns')\n",
    "scaler = StandardScaler()\n",
    "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**show features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>dist_interact</th>\n",
       "      <th>eem_0</th>\n",
       "      <th>mmff94_0</th>\n",
       "      <th>gasteiger_0</th>\n",
       "      <th>qeq_0</th>\n",
       "      <th>qtpie_0</th>\n",
       "      <th>eem2015ha_0</th>\n",
       "      <th>eem2015hm_0</th>\n",
       "      <th>eem2015hn_0</th>\n",
       "      <th>eem2015ba_0</th>\n",
       "      <th>eem2015bm_0</th>\n",
       "      <th>eem2015bn_0</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>eem_1</th>\n",
       "      <th>mmff94_1</th>\n",
       "      <th>gasteiger_1</th>\n",
       "      <th>qeq_1</th>\n",
       "      <th>qtpie_1</th>\n",
       "      <th>eem2015ha_1</th>\n",
       "      <th>eem2015hm_1</th>\n",
       "      <th>eem2015hn_1</th>\n",
       "      <th>eem2015ba_1</th>\n",
       "      <th>eem2015bm_1</th>\n",
       "      <th>eem2015bn_1</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>fc</th>\n",
       "      <th>type_0</th>\n",
       "      <th>dist</th>\n",
       "      <th>dist_x</th>\n",
       "      <th>dist_y</th>\n",
       "      <th>dist_z</th>\n",
       "      <th>molecule_couples</th>\n",
       "      <th>molecule_dist_mean</th>\n",
       "      <th>molecule_dist_min</th>\n",
       "      <th>molecule_dist_max</th>\n",
       "      <th>atom_0_couples_count</th>\n",
       "      <th>atom_1_couples_count</th>\n",
       "      <th>molecule_atom_index_0_x_1_std</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_y_1_max</th>\n",
       "      <th>molecule_atom_index_0_y_1_max_diff</th>\n",
       "      <th>molecule_atom_index_0_y_1_std</th>\n",
       "      <th>molecule_atom_index_0_z_1_std</th>\n",
       "      <th>molecule_atom_index_0_dist_mean</th>\n",
       "      <th>molecule_atom_index_0_dist_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_mean_div</th>\n",
       "      <th>molecule_atom_index_0_dist_max</th>\n",
       "      <th>molecule_atom_index_0_dist_max_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_max_div</th>\n",
       "      <th>molecule_atom_index_0_dist_min</th>\n",
       "      <th>molecule_atom_index_0_dist_min_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_min_div</th>\n",
       "      <th>molecule_atom_index_0_dist_std</th>\n",
       "      <th>molecule_atom_index_0_dist_std_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_std_div</th>\n",
       "      <th>molecule_atom_index_1_dist_mean</th>\n",
       "      <th>molecule_atom_index_1_dist_mean_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_mean_div</th>\n",
       "      <th>molecule_atom_index_1_dist_max</th>\n",
       "      <th>molecule_atom_index_1_dist_max_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_max_div</th>\n",
       "      <th>molecule_atom_index_1_dist_min</th>\n",
       "      <th>molecule_atom_index_1_dist_min_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_min_div</th>\n",
       "      <th>molecule_atom_index_1_dist_std</th>\n",
       "      <th>molecule_atom_index_1_dist_std_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_std_div</th>\n",
       "      <th>molecule_atom_1_dist_mean</th>\n",
       "      <th>molecule_atom_1_dist_min</th>\n",
       "      <th>molecule_atom_1_dist_min_diff</th>\n",
       "      <th>molecule_atom_1_dist_min_div</th>\n",
       "      <th>molecule_atom_1_dist_std</th>\n",
       "      <th>molecule_atom_1_dist_std_diff</th>\n",
       "      <th>molecule_type_0_dist_std</th>\n",
       "      <th>molecule_type_0_dist_std_diff</th>\n",
       "      <th>molecule_type_dist_mean</th>\n",
       "      <th>molecule_type_dist_mean_diff</th>\n",
       "      <th>molecule_type_dist_mean_div</th>\n",
       "      <th>molecule_type_dist_max</th>\n",
       "      <th>molecule_type_dist_min</th>\n",
       "      <th>molecule_type_dist_std</th>\n",
       "      <th>molecule_type_dist_std_diff</th>\n",
       "      <th>atom_index_closest_0</th>\n",
       "      <th>x_closest_0</th>\n",
       "      <th>y_closest_0</th>\n",
       "      <th>z_closest_0</th>\n",
       "      <th>atom_index_closest_1</th>\n",
       "      <th>x_closest_1</th>\n",
       "      <th>y_closest_1</th>\n",
       "      <th>z_closest_1</th>\n",
       "      <th>distance_0</th>\n",
       "      <th>distance_1</th>\n",
       "      <th>cos_0_1</th>\n",
       "      <th>cos_0</th>\n",
       "      <th>cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>-3.781511</td>\n",
       "      <td>-1.178221</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>-1.749500</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.499733</td>\n",
       "      <td>-0.957081</td>\n",
       "      <td>-1.643399</td>\n",
       "      <td>1.849852</td>\n",
       "      <td>-0.677664</td>\n",
       "      <td>-0.464361</td>\n",
       "      <td>-0.129878</td>\n",
       "      <td>-0.631481</td>\n",
       "      <td>-0.516885</td>\n",
       "      <td>-0.065988</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.058942</td>\n",
       "      <td>0.101017</td>\n",
       "      <td>-0.028857</td>\n",
       "      <td>-2.353260</td>\n",
       "      <td>-0.134372</td>\n",
       "      <td>-0.590919</td>\n",
       "      <td>2.500749</td>\n",
       "      <td>-2.627889</td>\n",
       "      <td>-0.220397</td>\n",
       "      <td>-2.200385</td>\n",
       "      <td>-2.429678</td>\n",
       "      <td>-0.423880</td>\n",
       "      <td>-2.000177</td>\n",
       "      <td>-2.638835</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074538</td>\n",
       "      <td>0.838297</td>\n",
       "      <td>-0.055478</td>\n",
       "      <td>1.972631</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.722481</td>\n",
       "      <td>-0.842808</td>\n",
       "      <td>-0.418013</td>\n",
       "      <td>-0.830647</td>\n",
       "      <td>-2.643478</td>\n",
       "      <td>-8.777096</td>\n",
       "      <td>0.842388</td>\n",
       "      <td>-17.888431</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.556914</td>\n",
       "      <td>1.177065</td>\n",
       "      <td>0.287480</td>\n",
       "      <td>0.297534</td>\n",
       "      <td>-0.954753</td>\n",
       "      <td>-3.02904</td>\n",
       "      <td>-0.462845</td>\n",
       "      <td>-4.628944</td>\n",
       "      <td>0.721346</td>\n",
       "      <td>0.709285</td>\n",
       "      <td>-6.266844</td>\n",
       "      <td>-0.315383</td>\n",
       "      <td>0.067509</td>\n",
       "      <td>-0.129872</td>\n",
       "      <td>1.685213</td>\n",
       "      <td>2.044782</td>\n",
       "      <td>-3.588055</td>\n",
       "      <td>1.114701</td>\n",
       "      <td>-0.350180</td>\n",
       "      <td>-3.476210</td>\n",
       "      <td>-5.328886e-06</td>\n",
       "      <td>-0.257917</td>\n",
       "      <td>-3.776541</td>\n",
       "      <td>-0.987156</td>\n",
       "      <td>-0.717324</td>\n",
       "      <td>-0.767633</td>\n",
       "      <td>1.022706</td>\n",
       "      <td>1.092895</td>\n",
       "      <td>-2.01175</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>-1.277446</td>\n",
       "      <td>-8.01584</td>\n",
       "      <td>-0.502063</td>\n",
       "      <td>1.393794</td>\n",
       "      <td>1.577592</td>\n",
       "      <td>-4.611330</td>\n",
       "      <td>0.730822</td>\n",
       "      <td>-1.871366</td>\n",
       "      <td>1.651783</td>\n",
       "      <td>-1.790897</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.068309</td>\n",
       "      <td>-1.689914</td>\n",
       "      <td>-1.876404</td>\n",
       "      <td>-1.181903</td>\n",
       "      <td>1.647381</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.080289</td>\n",
       "      <td>0.726165</td>\n",
       "      <td>-0.04609</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.373140</td>\n",
       "      <td>0.914106</td>\n",
       "      <td>-0.621102</td>\n",
       "      <td>-0.129872</td>\n",
       "      <td>-0.490765</td>\n",
       "      <td>0.698087</td>\n",
       "      <td>-1.215359</td>\n",
       "      <td>-0.661580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>-3.781511</td>\n",
       "      <td>-0.777737</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>-0.741271</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.499733</td>\n",
       "      <td>-0.957081</td>\n",
       "      <td>-1.643399</td>\n",
       "      <td>1.849852</td>\n",
       "      <td>-0.677664</td>\n",
       "      <td>-0.464361</td>\n",
       "      <td>-0.129878</td>\n",
       "      <td>-0.631481</td>\n",
       "      <td>-0.516885</td>\n",
       "      <td>-0.065988</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.058942</td>\n",
       "      <td>0.101017</td>\n",
       "      <td>-0.028857</td>\n",
       "      <td>0.849271</td>\n",
       "      <td>-0.134372</td>\n",
       "      <td>0.191465</td>\n",
       "      <td>-0.684059</td>\n",
       "      <td>0.717267</td>\n",
       "      <td>-0.266437</td>\n",
       "      <td>0.858001</td>\n",
       "      <td>0.879389</td>\n",
       "      <td>-0.168474</td>\n",
       "      <td>0.866440</td>\n",
       "      <td>1.022241</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617917</td>\n",
       "      <td>1.052165</td>\n",
       "      <td>-0.061629</td>\n",
       "      <td>-0.796477</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.784301</td>\n",
       "      <td>-0.406313</td>\n",
       "      <td>-0.033681</td>\n",
       "      <td>-0.830661</td>\n",
       "      <td>-2.643478</td>\n",
       "      <td>-8.777096</td>\n",
       "      <td>0.842388</td>\n",
       "      <td>-17.888431</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.556914</td>\n",
       "      <td>1.177065</td>\n",
       "      <td>-0.110587</td>\n",
       "      <td>0.297534</td>\n",
       "      <td>-1.305190</td>\n",
       "      <td>-3.02904</td>\n",
       "      <td>-0.462845</td>\n",
       "      <td>-4.628944</td>\n",
       "      <td>-0.240419</td>\n",
       "      <td>-0.489393</td>\n",
       "      <td>-6.266844</td>\n",
       "      <td>-1.241980</td>\n",
       "      <td>-0.861893</td>\n",
       "      <td>-0.129872</td>\n",
       "      <td>0.755201</td>\n",
       "      <td>0.340917</td>\n",
       "      <td>-3.588055</td>\n",
       "      <td>0.188345</td>\n",
       "      <td>-1.022697</td>\n",
       "      <td>-1.582825</td>\n",
       "      <td>1.222410e-19</td>\n",
       "      <td>-0.257909</td>\n",
       "      <td>-2.478166</td>\n",
       "      <td>-0.987156</td>\n",
       "      <td>-0.717324</td>\n",
       "      <td>0.481321</td>\n",
       "      <td>1.022714</td>\n",
       "      <td>1.092918</td>\n",
       "      <td>-2.01176</td>\n",
       "      <td>1.817684</td>\n",
       "      <td>-1.277458</td>\n",
       "      <td>-3.64969</td>\n",
       "      <td>1.655812</td>\n",
       "      <td>1.393802</td>\n",
       "      <td>1.577616</td>\n",
       "      <td>-4.611262</td>\n",
       "      <td>-0.188767</td>\n",
       "      <td>-1.871280</td>\n",
       "      <td>0.553795</td>\n",
       "      <td>-0.815413</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>-0.068049</td>\n",
       "      <td>-0.911640</td>\n",
       "      <td>-0.617287</td>\n",
       "      <td>-1.181825</td>\n",
       "      <td>0.601918</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.080289</td>\n",
       "      <td>0.726165</td>\n",
       "      <td>-0.04609</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.062445</td>\n",
       "      <td>0.733214</td>\n",
       "      <td>-0.033964</td>\n",
       "      <td>-0.129872</td>\n",
       "      <td>-0.490753</td>\n",
       "      <td>-0.404405</td>\n",
       "      <td>-0.282954</td>\n",
       "      <td>1.129537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001     -3.781511     -1.178221     0   \n",
       "1   1  dsgdb9nsd_000001     -3.781511     -0.777737     3   \n",
       "\n",
       "   scalar_coupling_constant  dist_interact     eem_0  mmff94_0  gasteiger_0  \\\n",
       "0                   84.8076      -1.749500  0.003098 -0.499733    -0.957081   \n",
       "1                  -11.2570      -0.741271  0.003098 -0.499733    -0.957081   \n",
       "\n",
       "      qeq_0   qtpie_0  eem2015ha_0  eem2015hm_0  eem2015hn_0  eem2015ba_0  \\\n",
       "0 -1.643399  1.849852    -0.677664    -0.464361    -0.129878    -0.631481   \n",
       "1 -1.643399  1.849852    -0.677664    -0.464361    -0.129878    -0.631481   \n",
       "\n",
       "   eem2015bm_0  eem2015bn_0 atom_0       x_0       y_0       z_0     eem_1  \\\n",
       "0    -0.516885    -0.065988      H -0.058942  0.101017 -0.028857 -2.353260   \n",
       "1    -0.516885    -0.065988      H -0.058942  0.101017 -0.028857  0.849271   \n",
       "\n",
       "   mmff94_1  gasteiger_1     qeq_1   qtpie_1  eem2015ha_1  eem2015hm_1  \\\n",
       "0 -0.134372    -0.590919  2.500749 -2.627889    -0.220397    -2.200385   \n",
       "1 -0.134372     0.191465 -0.684059  0.717267    -0.266437     0.858001   \n",
       "\n",
       "   eem2015hn_1  eem2015ba_1  eem2015bm_1  eem2015bn_1  atom_1       x_1  \\\n",
       "0    -2.429678    -0.423880    -2.000177    -2.638835       0 -0.074538   \n",
       "1     0.879389    -0.168474     0.866440     1.022241       1  0.617917   \n",
       "\n",
       "        y_1       z_1        fc  type_0      dist    dist_x    dist_y  \\\n",
       "0  0.838297 -0.055478  1.972631       0 -1.722481 -0.842808 -0.418013   \n",
       "1  1.052165 -0.061629 -0.796477       1 -0.784301 -0.406313 -0.033681   \n",
       "\n",
       "     dist_z  molecule_couples  molecule_dist_mean  molecule_dist_min  \\\n",
       "0 -0.830647         -2.643478           -8.777096           0.842388   \n",
       "1 -0.830661         -2.643478           -8.777096           0.842388   \n",
       "\n",
       "   molecule_dist_max  atom_0_couples_count  atom_1_couples_count  \\\n",
       "0         -17.888431                     4                     4   \n",
       "1         -17.888431                     4                     1   \n",
       "\n",
       "   molecule_atom_index_0_x_1_std  molecule_atom_index_0_y_1_mean  \\\n",
       "0                      -0.556914                        1.177065   \n",
       "1                      -0.556914                        1.177065   \n",
       "\n",
       "   molecule_atom_index_0_y_1_mean_diff  molecule_atom_index_0_y_1_max  \\\n",
       "0                             0.287480                       0.297534   \n",
       "1                            -0.110587                       0.297534   \n",
       "\n",
       "   molecule_atom_index_0_y_1_max_diff  molecule_atom_index_0_y_1_std  \\\n",
       "0                           -0.954753                       -3.02904   \n",
       "1                           -1.305190                       -3.02904   \n",
       "\n",
       "   molecule_atom_index_0_z_1_std  molecule_atom_index_0_dist_mean  \\\n",
       "0                      -0.462845                        -4.628944   \n",
       "1                      -0.462845                        -4.628944   \n",
       "\n",
       "   molecule_atom_index_0_dist_mean_diff  molecule_atom_index_0_dist_mean_div  \\\n",
       "0                              0.721346                             0.709285   \n",
       "1                             -0.240419                            -0.489393   \n",
       "\n",
       "   molecule_atom_index_0_dist_max  molecule_atom_index_0_dist_max_diff  \\\n",
       "0                       -6.266844                            -0.315383   \n",
       "1                       -6.266844                            -1.241980   \n",
       "\n",
       "   molecule_atom_index_0_dist_max_div  molecule_atom_index_0_dist_min  \\\n",
       "0                            0.067509                       -0.129872   \n",
       "1                           -0.861893                       -0.129872   \n",
       "\n",
       "   molecule_atom_index_0_dist_min_diff  molecule_atom_index_0_dist_min_div  \\\n",
       "0                             1.685213                            2.044782   \n",
       "1                             0.755201                            0.340917   \n",
       "\n",
       "   molecule_atom_index_0_dist_std  molecule_atom_index_0_dist_std_diff  \\\n",
       "0                       -3.588055                             1.114701   \n",
       "1                       -3.588055                             0.188345   \n",
       "\n",
       "   molecule_atom_index_0_dist_std_div  molecule_atom_index_1_dist_mean  \\\n",
       "0                           -0.350180                        -3.476210   \n",
       "1                           -1.022697                        -1.582825   \n",
       "\n",
       "   molecule_atom_index_1_dist_mean_diff  molecule_atom_index_1_dist_mean_div  \\\n",
       "0                         -5.328886e-06                            -0.257917   \n",
       "1                          1.222410e-19                            -0.257909   \n",
       "\n",
       "   molecule_atom_index_1_dist_max  molecule_atom_index_1_dist_max_diff  \\\n",
       "0                       -3.776541                            -0.987156   \n",
       "1                       -2.478166                            -0.987156   \n",
       "\n",
       "   molecule_atom_index_1_dist_max_div  molecule_atom_index_1_dist_min  \\\n",
       "0                           -0.717324                       -0.767633   \n",
       "1                           -0.717324                        0.481321   \n",
       "\n",
       "   molecule_atom_index_1_dist_min_diff  molecule_atom_index_1_dist_min_div  \\\n",
       "0                             1.022706                            1.092895   \n",
       "1                             1.022714                            1.092918   \n",
       "\n",
       "   molecule_atom_index_1_dist_std  molecule_atom_index_1_dist_std_diff  \\\n",
       "0                        -2.01175                             0.571017   \n",
       "1                        -2.01176                             1.817684   \n",
       "\n",
       "   molecule_atom_index_1_dist_std_div  molecule_atom_1_dist_mean  \\\n",
       "0                           -1.277446                   -8.01584   \n",
       "1                           -1.277458                   -3.64969   \n",
       "\n",
       "   molecule_atom_1_dist_min  molecule_atom_1_dist_min_diff  \\\n",
       "0                 -0.502063                       1.393794   \n",
       "1                  1.655812                       1.393802   \n",
       "\n",
       "   molecule_atom_1_dist_min_div  molecule_atom_1_dist_std  \\\n",
       "0                      1.577592                 -4.611330   \n",
       "1                      1.577616                 -4.611262   \n",
       "\n",
       "   molecule_atom_1_dist_std_diff  molecule_type_0_dist_std  \\\n",
       "0                       0.730822                 -1.871366   \n",
       "1                      -0.188767                 -1.871280   \n",
       "\n",
       "   molecule_type_0_dist_std_diff  molecule_type_dist_mean  \\\n",
       "0                       1.651783                -1.790897   \n",
       "1                       0.553795                -0.815413   \n",
       "\n",
       "   molecule_type_dist_mean_diff  molecule_type_dist_mean_div  \\\n",
       "0                     -0.000017                    -0.068309   \n",
       "1                      0.000132                    -0.068049   \n",
       "\n",
       "   molecule_type_dist_max  molecule_type_dist_min  molecule_type_dist_std  \\\n",
       "0               -1.689914               -1.876404               -1.181903   \n",
       "1               -0.911640               -0.617287               -1.181825   \n",
       "\n",
       "   molecule_type_dist_std_diff  atom_index_closest_0  x_closest_0  \\\n",
       "0                     1.647381                     0    -0.080289   \n",
       "1                     0.601918                     0    -0.080289   \n",
       "\n",
       "   y_closest_0  z_closest_0  atom_index_closest_1  x_closest_1  y_closest_1  \\\n",
       "0     0.726165     -0.04609                     3    -0.373140     0.914106   \n",
       "1     0.726165     -0.04609                     0    -0.062445     0.733214   \n",
       "\n",
       "   z_closest_1  distance_0  distance_1   cos_0_1     cos_0     cos_1  \n",
       "0    -0.621102   -0.129872   -0.490765  0.698087 -1.215359 -0.661580  \n",
       "1    -0.033964   -0.129872   -0.490753 -0.404405 -0.282954  1.129537  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
      "       'dist_interact', 'eem_0', 'mmff94_0', 'gasteiger_0', 'qeq_0',\n",
      "       ...\n",
      "       'z_closest_0', 'atom_index_closest_1', 'x_closest_1', 'y_closest_1',\n",
      "       'z_closest_1', 'distance_0', 'distance_1', 'cos_0_1', 'cos_0', 'cos_1'],\n",
      "      dtype='object', length=107)\n"
     ]
    }
   ],
   "source": [
    "print(len(test.columns))\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3638.29 Mb (6.1% reduction)\n",
      "Mem. usage decreased to 1937.86 Mb (6.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test  = reduce_mem_usage(test)\n",
    "y = train['scalar_coupling_constant']\n",
    "train = train.drop(['id', 'molecule_name', 'atom_0', 'scalar_coupling_constant'], axis=1)\n",
    "test  =  test.drop(['id', 'molecule_name', 'atom_0'], axis=1)\n",
    "\n",
    "X = train.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "assert len(X.columns) == len(X_test.columns), f'X と X_test のサイズが違います X: {len(X.columns)}, X_test: {len(X_test.columns)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- set params -----\n",
    "n_folds = 4\n",
    "# batch_size = 200\n",
    "batch_size = int(1024 * 2 * 8)\n",
    "train_epochs = 150\n",
    "VERBOSE = 30\n",
    "n_feats =  X.shape[1]\n",
    "# -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=n_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# analysis\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in progress_bar([i * 0.01 for i in range(100)]):\n",
    "        score = accuracy_score(y_true=y_true, y_pred=y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'accuracy_score': best_score}\n",
    "    return search_result\n",
    "\n",
    "# Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, out_features, p=0.2, bias=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc0 = nn.Linear(in_features, 100, bias)\n",
    "        self.bn0 = nn.BatchNorm1d(100)\n",
    "        \n",
    "        self.fc1 = nn.Linear(100, 512, bias)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 1024, bias)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024, 1024, bias)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.fc4 = nn.Linear(1024, 512, bias)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc5 = nn.Linear(512, 512, bias)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc6 = nn.Linear(512, 256, bias)\n",
    "        self.bn6 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc7 = nn.Linear(256, 256, bias)\n",
    "        self.bn7 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc8 = nn.Linear(256, 128, bias)\n",
    "        self.bn8 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc8 = nn.Linear(256, 128, bias)\n",
    "        self.bn8 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc9 = nn.Linear(128, 64, bias)\n",
    "        self.bn9 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc10= nn.Linear(64, out_features)\n",
    "        \n",
    "        \n",
    "        # その他\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc9(x)\n",
    "        x = self.bn9(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.fc10(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "- Fold 1/4\n",
      "Fold 1 started at Wed Aug  7 05:07:09 2019\n",
      "Epoch 30/150 \t loss=1.9438 \t val_loss=1.1280 \t time=48.29s\n",
      "Epoch 60/150 \t loss=1.7287 \t val_loss=1.2109 \t time=48.03s\n",
      "Epoch 90/150 \t loss=1.6435 \t val_loss=1.3228 \t time=48.27s\n",
      "Epoch 120/150 \t loss=1.6125 \t val_loss=1.4109 \t time=48.06s\n",
      "Epoch 150/150 \t loss=1.5932 \t val_loss=1.3817 \t time=48.19s\n",
      "----------------------------------------------------------------------\n",
      "- Fold 2/4\n",
      "Fold 2 started at Wed Aug  7 06:43:27 2019\n",
      "Epoch 30/150 \t loss=1.9404 \t val_loss=1.1170 \t time=48.35s\n",
      "Epoch 60/150 \t loss=1.7202 \t val_loss=1.3507 \t time=48.37s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Kfold のループ部分\n",
    "train_preds = np.zeros((len(X)))\n",
    "test_preds  = np.zeros((len(X_test)))\n",
    "for i, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "\n",
    "    # X, y, X_val, y_val をテンソル化(PyTorch で扱える形に変換)し、 .cuda() (GPUで計算するために特徴量を GPU に渡す処理)をする。\n",
    "    X_train_fold = torch.tensor(X.iloc[train_idx, :].values, dtype=torch.float32)\n",
    "    X_val_fold   = torch.tensor(X.iloc[valid_idx, :].values, dtype=torch.float32)\n",
    "    X_test_      = torch.tensor(X_test.iloc[:,:].values, dtype=torch.float32) \n",
    "    y_train_fold = torch.tensor(y[train_idx, np.newaxis], dtype=torch.float32)\n",
    "    y_val_fold   = torch.tensor(y[valid_idx, np.newaxis], dtype=torch.float32)\n",
    "    \n",
    "    # model を呼び出し\n",
    "    model = Model(n_feats, 1)\n",
    "    \n",
    "    # gpu 使えるならcudaに渡す\n",
    "    if is_cuda:\n",
    "        X_train_fold = X_train_fold.cuda()\n",
    "        y_train_fold = y_train_fold.cuda()\n",
    "        X_val_fold   = X_val_fold.cuda()\n",
    "        y_val_fold   = y_val_fold.cuda()\n",
    "        model = model.cuda()\n",
    "        model = nn.DataParallel(model) # make parallel\n",
    "#         model = nn.DataParallel(model).cuda() # マルチGPU\n",
    "#         cudnn.benchmark = True\n",
    "    \n",
    "    # loss 関数を呼び出す。BCELoss() よりも好まれるらしい。。\n",
    "#     loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # dataloader で扱える形( = Dataset )にする\n",
    "    train_ = torch.utils.data.TensorDataset(X_train_fold, y_train_fold)\n",
    "    valid_ = torch.utils.data.TensorDataset(X_val_fold, y_val_fold)\n",
    "    test_  = torch.utils.data.TensorDataset(X_test_)\n",
    "    \n",
    "    # X_train_fold batch_size個, y_train_fold batch_size個ずつを各ループで返す iterater の定義\n",
    "    train_loader = torch.utils.data.DataLoader(train_, batch_size=batch_size, shuffle=True)\n",
    "    # X_valid_fold batch_size個, y_valid_fold batch_size個ずつを各ループで返す iterater の定義\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_, batch_size=batch_size, shuffle=False)\n",
    "    # X_test batch_size個, y_valid_fold batch_size個ずつを各ループで返す iterater の定義\n",
    "    test_loader = torch.utils.data.DataLoader(test_, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print('-'*70)\n",
    "    print(f'- Fold {i + 1}/{n_folds}')\n",
    "    print(f'Fold {i + 1} started at {time.ctime()}')\n",
    "    \n",
    "    # epoch 分のループを回す\n",
    "    for epoch in range(train_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # model を train mode にする\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "\n",
    "        # X_train_fold と y_train_fold を batch_size 個ずつ渡すループ\n",
    "#         for X_batch, y_batch in progress_bar(train_loader):\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # predict\n",
    "            y_pred = model.forward(X_batch)\n",
    "            # loss の計算\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        if ((epoch+1)%VERBOSE==0) or (epoch+1==train_epochs):\n",
    "            model.eval()\n",
    "            valid_preds_fold = np.zeros((X_val_fold.size(0)))\n",
    "            test_preds_fold = np.zeros(len(X_test_))\n",
    "            avg_val_loss = 0.\n",
    "            for i, (X_batch, y_batch) in enumerate(valid_loader):\n",
    "                y_pred = model(X_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                valid_preds_fold[i * batch_size:(i+1) * batch_size] = y_pred.cpu().numpy()[:, 0] #sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, train_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "\n",
    "    # X_test_fold を batch_size ずつ渡すループ    \n",
    "    for i, (X_batch,) in enumerate(test_loader):\n",
    "        y_pred = model(X_batch).detach()\n",
    "\n",
    "        # batch_size のリストのリストになっているのを単一階層のリストに変換して、cpuに値を渡し、テンソルから numpy.array()に変換したものを sigmoid 関数に渡す\n",
    "        test_preds_fold[i * batch_size:(i+1) * batch_size] = y_pred.cpu().numpy()[:, 0] #sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "    train_preds[valid_idx] = valid_preds_fold\n",
    "\n",
    "    # 予測値の kfold数で割った値を加える\n",
    "    test_preds += test_preds_fold / n_folds\n",
    "    \n",
    "X['scalar_coupling_constant'] = y\n",
    "cv_score = kaggle_metric(X, train_preds)\n",
    "X = X.drop(['scalar_coupling_constant', 'prediction'], axis=1)\n",
    "print('\\n CV mean score(group log mae): {0:.4f}\\n'.format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d2f97026885c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_submittion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../output/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'nb{}_submission_nn_{:.4f}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# path_submittion = 'nb{}_submission_lgb_{}.csv'.format(nb, cv_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'save pash: {path_submittion}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv_score' is not defined"
     ]
    }
   ],
   "source": [
    "path_submittion = '../output/' + 'nb{}_submission_nn_{:.4f}.csv'.format(nb, cv_score)\n",
    "# path_submittion = 'nb{}_submission_lgb_{}.csv'.format(nb, cv_score)\n",
    "print(f'save pash: {path_submittion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submittion = pd.read_csv('../input/champs-scalar-coupling/sample_submission.csv')\n",
    "# submittion = pd.read_csv('./input/champs-scalar-coupling/sample_submission.csv')[:100]\n",
    "if isSmallSet :\n",
    "    print('using small set')\n",
    "else :\n",
    "    submittion['scalar_coupling_constant'] = test_preds\n",
    "    submittion.to_csv(path_submittion, index=False)  if not isSmallSet else print('using small set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_oof = '../output/' + 'nb{}_oof_nn_{:.4f}.csv'.format(nb, cv_score)\n",
    "print(f'save pash: {path_oof}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isSmallSet:\n",
    "    print('using small set')\n",
    "else :\n",
    "    oof = pd.DataFrame({'oof':train_preds})\n",
    "    oof.to_csv(path_oof, index=False) if not isSmallSet else print('using small set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame(y)\n",
    "plot_data.index.name = 'id'\n",
    "plot_data['yhat'] = train_preds\n",
    "plot_data['type'] = lbl.inverse_transform(X['type'])\n",
    "\n",
    "def plot_oof_preds(ctype, llim, ulim):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        sns.scatterplot(x='scalar_coupling_constant',y='yhat',\n",
    "                        data=plot_data.loc[plot_data['type']==ctype,\n",
    "                        ['scalar_coupling_constant', 'yhat']]);\n",
    "        plt.xlim((llim, ulim))\n",
    "        plt.ylim((llim, ulim))\n",
    "        plt.plot([llim, ulim], [llim, ulim])\n",
    "        plt.xlabel('scalar_coupling_constant')\n",
    "        plt.ylabel('predicted')\n",
    "        plt.title(f'{ctype}', fontsize=18)\n",
    "        plt.show()\n",
    "\n",
    "plot_oof_preds(0, 20, 250)\n",
    "plot_oof_preds(1, 10, 100)\n",
    "plot_oof_preds(2, -40, 50)\n",
    "plot_oof_preds(3, -50, 30)\n",
    "plot_oof_preds(4, -25, 25)\n",
    "plot_oof_preds(5, -40, 90)\n",
    "plot_oof_preds(6, -20, 20)\n",
    "plot_oof_preds(7, -10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

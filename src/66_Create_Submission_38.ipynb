{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- nb60の編集\n",
    "- n_estimator を小さめにする\n",
    "- いくつかのrandom_seedでモデルを作り保存する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import multiprocessing\n",
    "import glob\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 66\n",
    "isSmallSet = False\n",
    "length = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use atomic numbers to recode atomic names\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/champs-scalar-coupling/scalar_coupling_contributions.csv',\n",
       " '../input/champs-scalar-coupling/magnetic_shielding_tensors.csv',\n",
       " '../input/champs-scalar-coupling/structures.csv',\n",
       " '../input/champs-scalar-coupling/test.csv',\n",
       " '../input/champs-scalar-coupling/dipole_moments.csv',\n",
       " '../input/champs-scalar-coupling/potential_energy.csv',\n",
       " '../input/champs-scalar-coupling/sample_submission.csv',\n",
       " '../input/champs-scalar-coupling/nb47_fc_train.csv',\n",
       " '../input/champs-scalar-coupling/train.csv',\n",
       " '../input/champs-scalar-coupling/nb33_train_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_test_feature.csv',\n",
       " '../input/champs-scalar-coupling/train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv',\n",
       " '../input/champs-scalar-coupling/nb33_test_dist-interaction.csv',\n",
       " '../input/champs-scalar-coupling/mulliken_charges.csv',\n",
       " '../input/champs-scalar-coupling/nb47_fc_test.csv',\n",
       " '../input/champs-scalar-coupling/nb29_fc_train_feature.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../input/champs-scalar-coupling/'\n",
    "glob.glob(file_path + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "path = file_path + 'train.csv'\n",
    "if isSmallSet:\n",
    "    train = pd.read_csv(path) [:length]\n",
    "else:\n",
    "    train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = file_path + 'test.csv'\n",
    "if isSmallSet:\n",
    "    test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure\n",
    "path = file_path + 'structures.csv'\n",
    "structures = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_train\n",
    "path = file_path + 'nb47_fc_train.csv'\n",
    "if isSmallSet:\n",
    "    fc_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_test\n",
    "path = file_path + 'nb47_fc_test.csv'\n",
    "if isSmallSet:\n",
    "    fc_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    fc_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dist-interact\n",
    "path = file_path + 'nb33_train_dist-interaction.csv'\n",
    "if isSmallSet:\n",
    "    dist_interact_train = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    dist_interact_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dist-interact\n",
    "path = file_path + 'nb33_test_dist-interaction.csv'\n",
    "if isSmallSet:\n",
    "    dist_interact_test = pd.read_csv(path)[:length]\n",
    "else:\n",
    "    dist_interact_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge train\n",
    "path = file_path + 'train_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_train = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_train = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob charge test\n",
    "path = file_path + 'test_ob_charges_V7EstimatioofMullikenChargeswithOpenBabel.csv'\n",
    "if isSmallSet:\n",
    "    ob_charge_test = pd.read_csv(path)[:length].drop(['Unnamed: 0', 'error'], axis=1)\n",
    "else:\n",
    "    ob_charge_test = pd.read_csv(path).drop(['Unnamed: 0', 'error'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 2505542)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(fc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 4658147)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(fc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4658147 rows in train data.\n",
      "There are 2505542 rows in test data.\n",
      "There are 85003 distinct molecules in train data.\n",
      "There are 45772 distinct molecules in test data.\n",
      "There are 29 unique atoms.\n",
      "There are 8 unique types.\n"
     ]
    }
   ],
   "source": [
    "if isSmallSet:\n",
    "    print('using SmallSet !!')\n",
    "    print('-------------------')\n",
    "\n",
    "print(f'There are {train.shape[0]} rows in train data.')\n",
    "print(f'There are {test.shape[0]} rows in test data.')\n",
    "\n",
    "print(f\"There are {train['molecule_name'].nunique()} distinct molecules in train data.\")\n",
    "print(f\"There are {test['molecule_name'].nunique()} distinct molecules in test data.\")\n",
    "print(f\"There are {train['atom_index_0'].nunique()} unique atoms.\")\n",
    "print(f\"There are {train['type'].nunique()} unique types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## myFunc\n",
    "**metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_metric(df, preds):\n",
    "    df[\"prediction\"] = preds\n",
    "    maes = []\n",
    "    for t in df.type.unique():\n",
    "        y_true = df[df.type==t].scalar_coupling_constant.values\n",
    "        y_pred = df[df.type==t].prediction.values\n",
    "        mae = np.log(mean_absolute_error(y_true, y_pred))\n",
    "        maes.append(mae)\n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**momory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Distance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_name'].isin(base['molecule_name'])]\n",
    "    return base, structures\n",
    "\n",
    "# a,b = build_type_dataframes(train, structures, '1JHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_name', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_name', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_name', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_name'],\n",
    "                  right_on=['molecule_name'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        (df['x_c'] - df['x'])**np.float32(2) +\n",
    "        (df['y_c'] - df['y'])**np.float32(2) + \n",
    "        (df['z_c'] - df['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_name'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_name', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_name', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_name', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "#     # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "#     atoms['molecule_name'] = atoms['molecule_name'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = ['id', 'molecule_name', 'atom_index_1', 'atom_index_0']\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    return df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8/8 07:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "atoms = structures['atom'].values\n",
    "types_train = train['type'].values\n",
    "types_test = test['type'].values\n",
    "structures['atom'] = structures['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "fulls_train = []\n",
    "fulls_test  = []\n",
    "for type_ in progress_bar(train['type'].unique()):\n",
    "    full_train = build_couple_dataframe(train, structures, type_, n_atoms=10)\n",
    "    full_test  = build_couple_dataframe(test, structures, type_, n_atoms=10)\n",
    "    full_train = take_n_atoms(full_train, 10)\n",
    "    full_test  = take_n_atoms(full_test, 10)\n",
    "    fulls_train.append(full_train)\n",
    "    fulls_test.append(full_test)\n",
    "    \n",
    "structures['atom'] = atoms\n",
    "train = pd.concat(fulls_train).sort_values(by=['id']) #, axis=0)\n",
    "test  = pd.concat(fulls_test).sort_values(by=['id']) #, axis=0)\n",
    "train['type'] = types_train\n",
    "test['type'] = types_test\n",
    "train = train.fillna(0)\n",
    "test  = test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "dist-interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dist_interact'] = dist_interact_train.values\n",
    "test['dist_interact'] = dist_interact_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>d_1_0</th>\n",
       "      <th>d_2_0</th>\n",
       "      <th>d_2_1</th>\n",
       "      <th>d_3_0</th>\n",
       "      <th>d_3_1</th>\n",
       "      <th>d_3_2</th>\n",
       "      <th>d_4_0</th>\n",
       "      <th>d_4_1</th>\n",
       "      <th>d_4_2</th>\n",
       "      <th>d_4_3</th>\n",
       "      <th>d_5_0</th>\n",
       "      <th>d_5_1</th>\n",
       "      <th>d_5_2</th>\n",
       "      <th>d_5_3</th>\n",
       "      <th>d_6_0</th>\n",
       "      <th>d_6_1</th>\n",
       "      <th>d_6_2</th>\n",
       "      <th>d_6_3</th>\n",
       "      <th>d_7_0</th>\n",
       "      <th>d_7_1</th>\n",
       "      <th>d_7_2</th>\n",
       "      <th>d_7_3</th>\n",
       "      <th>d_8_0</th>\n",
       "      <th>d_8_1</th>\n",
       "      <th>d_8_2</th>\n",
       "      <th>d_8_3</th>\n",
       "      <th>d_9_0</th>\n",
       "      <th>d_9_1</th>\n",
       "      <th>d_9_2</th>\n",
       "      <th>d_9_3</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>type</th>\n",
       "      <th>dist_interact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>1.091953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>2.183905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>2.183899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>2.183901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>1.091952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_1  atom_index_0  atom_2  atom_3  atom_4  \\\n",
       "0   0  dsgdb9nsd_000001             0             1       1       1       1   \n",
       "0   1  dsgdb9nsd_000001             2             1       6       1       1   \n",
       "1   2  dsgdb9nsd_000001             3             1       6       1       1   \n",
       "3   3  dsgdb9nsd_000001             4             1       6       1       1   \n",
       "1   4  dsgdb9nsd_000001             0             2       1       1       1   \n",
       "\n",
       "   atom_5  atom_6  atom_7  atom_8  atom_9     d_1_0     d_2_0     d_2_1  \\\n",
       "0       0       0       0       0       0  1.091953  1.783120  1.091952   \n",
       "0       0       0       0       0       0  1.783120  1.091953  1.091952   \n",
       "1       0       0       0       0       0  1.783147  1.091953  1.091946   \n",
       "3       0       0       0       0       0  1.783157  1.091953  1.091948   \n",
       "1       0       0       0       0       0  1.091952  1.783120  1.091953   \n",
       "\n",
       "      d_3_0     d_3_1     d_3_2     d_4_0     d_4_1     d_4_2     d_4_3  \\\n",
       "0  1.783147  1.091946  1.783158  1.783157  1.091948  1.783148  1.783148   \n",
       "0  1.783157  1.783148  1.091948  1.783147  1.783158  1.091946  1.783148   \n",
       "1  1.783120  1.783158  1.091952  1.783157  1.783148  1.091948  1.783148   \n",
       "3  1.783120  1.783148  1.091952  1.783147  1.783148  1.091946  1.783158   \n",
       "1  1.783148  1.091948  1.783157  1.783158  1.091946  1.783147  1.783148   \n",
       "\n",
       "   d_5_0  d_5_1  d_5_2  d_5_3  d_6_0  d_6_1  d_6_2  d_6_3  d_7_0  d_7_1  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   d_7_2  d_7_3  d_8_0  d_8_1  d_8_2  d_8_3  d_9_0  d_9_1  d_9_2  d_9_3  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   scalar_coupling_constant  type  dist_interact  \n",
       "0                   84.8076  1JHC       1.091953  \n",
       "0                  -11.2570  2JHH       2.183905  \n",
       "1                  -11.2548  2JHH       2.183899  \n",
       "3                  -11.2543  2JHH       2.183901  \n",
       "1                   84.8074  1JHC       1.091952  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# structure and ob_charges\n",
    "ob_charge = pd.concat([ob_charge_train, ob_charge_test])\n",
    "merge = pd.merge(ob_charge, structures, how='left',\n",
    "                  left_on  = ['molecule_name', 'atom_index'],\n",
    "                  right_on = ['molecule_name', 'atom_index'])\n",
    "for atom_idx in [0,1]:\n",
    "    train = map_atom_info(train, merge, atom_idx)\n",
    "    test  = map_atom_info(test,  merge, atom_idx)\n",
    "    \n",
    "    train = train.rename(columns={\n",
    "                                        'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}',\n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}',})\n",
    "    test = test.rename(columns={\n",
    "                                        'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'eem': f'eem_{atom_idx}',\n",
    "                                     'mmff94': f'mmff94_{atom_idx}',\n",
    "                                  'gasteiger': f'gasteiger_{atom_idx}', \n",
    "                                        'qeq': f'qeq_{atom_idx}', \n",
    "                                      'qtpie': f'qtpie_{atom_idx}', \n",
    "                                  'eem2015ha': f'eem2015ha_{atom_idx}', \n",
    "                                  'eem2015hm': f'eem2015hm_{atom_idx}', \n",
    "                                  'eem2015hn': f'eem2015hn_{atom_idx}', \n",
    "                                  'eem2015ba': f'eem2015ba_{atom_idx}', \n",
    "                                  'eem2015bm': f'eem2015bm_{atom_idx}', \n",
    "                                  'eem2015bn': f'eem2015bn_{atom_idx}'})\n",
    "#     test  =  test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "#                                         'x': f'x_{atom_idx}',\n",
    "#                                         'y': f'y_{atom_idx}',\n",
    "#                                         'z': f'z_{atom_idx}'})\n",
    "\n",
    "# ob_charges\n",
    "# train = map_atom_info(train, ob_charge_train, 0)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  0)\n",
    "# train = map_atom_info(train, ob_charge_train, 1)\n",
    "# test  = map_atom_info(test,  ob_charge_test,  1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "type0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type0(df):\n",
    "    df['type_0'] = df['type'].apply(lambda x : x[0])\n",
    "    return df\n",
    "# train['type_0'] = train['type'].apply(lambda x: x[0])\n",
    "# test['type_0'] = test['type'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(df):\n",
    "    df_p_0 = df[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df[['x_1', 'y_1', 'z_1']].values\n",
    "    \n",
    "    df['dist'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "    df['dist_x'] = (df['x_0'] - df['x_1']) ** 2\n",
    "    df['dist_y'] = (df['y_0'] - df['y_1']) ** 2\n",
    "    df['dist_z'] = (df['z_0'] - df['z_1']) ** 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "# train = distances(train)\n",
    "# test  = distances(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "統計量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "    # fc\n",
    "    df[f'molecule_type_fc_max'] = df.groupby(['molecule_name', 'type'])['fc'].transform('max')\n",
    "    df[f'molecule_type_fc_min'] = df.groupby(['molecule_name', 'type'])['fc'].transform('min')\n",
    "    df[f'molecule_type_fc_std'] = df.groupby(['molecule_name', 'type'])['fc'].transform('std')\n",
    "    df[f'molecule_type_fc_std_diff'] = df[f'molecule_type_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_fc_mean_diff'] = df[f'molecule_atom_index_0_fc_mean'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_mean_div'] = df[f'molecule_atom_index_0_fc_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_fc_max'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('max')\n",
    "    df[f'molecule_atom_index_0_fc_max_diff'] = df[f'molecule_atom_index_0_fc_max'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_max_div'] = df[f'molecule_atom_index_0_fc_max'] / df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_min'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('min')\n",
    "    df[f'molecule_atom_index_0_fc_min_diff'] = df[f'molecule_atom_index_0_fc_min'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_min_div'] = df[f'molecule_atom_index_0_fc_min'] / df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_std'] = df.groupby(['molecule_name', 'atom_index_0'])['fc'].transform('std')\n",
    "    df[f'molecule_atom_index_0_fc_std_diff'] = df[f'molecule_atom_index_0_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_0_fc_std_div'] = df[f'molecule_atom_index_0_fc_std'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_fc_mean_diff'] = df[f'molecule_atom_index_1_fc_mean'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_mean_div'] = df[f'molecule_atom_index_1_fc_mean'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_max'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('max')\n",
    "    df[f'molecule_atom_index_1_fc_max_diff'] = df[f'molecule_atom_index_1_fc_max'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_max_div'] = df[f'molecule_atom_index_1_fc_max'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_min'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('min')\n",
    "    df[f'molecule_atom_index_1_fc_min_diff'] = df[f'molecule_atom_index_1_fc_min'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_min_div'] = df[f'molecule_atom_index_1_fc_min'] / df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_std'] = df.groupby(['molecule_name', 'atom_index_1'])['fc'].transform('std')\n",
    "    df[f'molecule_atom_index_1_fc_std_diff'] = df[f'molecule_atom_index_1_fc_std'] - df['fc']\n",
    "    df[f'molecule_atom_index_1_fc_std_div'] = df[f'molecule_atom_index_1_fc_std'] / df['fc']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "angle features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_closest(df):\n",
    "    df_temp=df.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"dist\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"dist\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance', 'dist'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                        'x_closest': f'x_closest_{atom_idx}',\n",
    "                                        'y_closest': f'y_closest_{atom_idx}',\n",
    "                                        'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "def add_cos_features(df):\n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"dist\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"dist\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"dist\"]\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add fc\n",
      "4658147 2505542\n",
      "type0\n",
      "4658147 2505542\n",
      "distances\n",
      "4658147 2505542\n",
      "create_featueres\n",
      "4658147 2505542\n",
      "create_closest\n",
      "4658147 2505542\n",
      "add_cos_features\n",
      "4658147 2505542\n",
      "CPU times: user 3min, sys: 4min 44s, total: 7min 44s\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('add fc')\n",
    "print(len(train), len(test))\n",
    "train['fc'] = fc_train.values\n",
    "test['fc']  = fc_test.values\n",
    "\n",
    "print('type0')\n",
    "print(len(train), len(test))\n",
    "train = create_type0(train)\n",
    "test  = create_type0(test)\n",
    "\n",
    "print('distances')\n",
    "print(len(train), len(test))\n",
    "train = distances(train)\n",
    "test  = distances(test)\n",
    "\n",
    "print('create_featueres')\n",
    "print(len(train), len(test))\n",
    "train = create_features(train)\n",
    "test  = create_features(test)\n",
    "\n",
    "print('create_closest')\n",
    "print(len(train), len(test))\n",
    "train = create_closest(train)\n",
    "test  = create_closest(test)\n",
    "train.drop_duplicates(inplace=True, subset=['id'])   # なぜかtrainの行数が増えるバグが発生\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print('add_cos_features')\n",
    "print(len(train), len(test))\n",
    "train = add_cos_features(train)\n",
    "test  = add_cos_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "<br>\n",
    "LabelEncode\n",
    "\n",
    "- `atom_1` = {H, C, N}\n",
    "- `type_0` = {1, 2, 3}\n",
    "- `type`   = {2JHC, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['atom_1', 'type_0', 'type']:\n",
    "    if f in train.columns:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**show features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>d_1_0</th>\n",
       "      <th>d_2_0</th>\n",
       "      <th>d_2_1</th>\n",
       "      <th>d_3_0</th>\n",
       "      <th>d_3_1</th>\n",
       "      <th>d_3_2</th>\n",
       "      <th>d_4_0</th>\n",
       "      <th>d_4_1</th>\n",
       "      <th>d_4_2</th>\n",
       "      <th>d_4_3</th>\n",
       "      <th>d_5_0</th>\n",
       "      <th>d_5_1</th>\n",
       "      <th>d_5_2</th>\n",
       "      <th>d_5_3</th>\n",
       "      <th>d_6_0</th>\n",
       "      <th>d_6_1</th>\n",
       "      <th>d_6_2</th>\n",
       "      <th>d_6_3</th>\n",
       "      <th>d_7_0</th>\n",
       "      <th>d_7_1</th>\n",
       "      <th>d_7_2</th>\n",
       "      <th>d_7_3</th>\n",
       "      <th>d_8_0</th>\n",
       "      <th>d_8_1</th>\n",
       "      <th>d_8_2</th>\n",
       "      <th>d_8_3</th>\n",
       "      <th>d_9_0</th>\n",
       "      <th>d_9_1</th>\n",
       "      <th>d_9_2</th>\n",
       "      <th>d_9_3</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>type</th>\n",
       "      <th>dist_interact</th>\n",
       "      <th>eem_0</th>\n",
       "      <th>mmff94_0</th>\n",
       "      <th>gasteiger_0</th>\n",
       "      <th>qeq_0</th>\n",
       "      <th>qtpie_0</th>\n",
       "      <th>eem2015ha_0</th>\n",
       "      <th>eem2015hm_0</th>\n",
       "      <th>eem2015hn_0</th>\n",
       "      <th>eem2015ba_0</th>\n",
       "      <th>eem2015bm_0</th>\n",
       "      <th>eem2015bn_0</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>eem_1</th>\n",
       "      <th>mmff94_1</th>\n",
       "      <th>gasteiger_1</th>\n",
       "      <th>qeq_1</th>\n",
       "      <th>qtpie_1</th>\n",
       "      <th>eem2015ha_1</th>\n",
       "      <th>eem2015hm_1</th>\n",
       "      <th>eem2015hn_1</th>\n",
       "      <th>eem2015ba_1</th>\n",
       "      <th>eem2015bm_1</th>\n",
       "      <th>eem2015bn_1</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>fc</th>\n",
       "      <th>type_0</th>\n",
       "      <th>dist</th>\n",
       "      <th>dist_x</th>\n",
       "      <th>dist_y</th>\n",
       "      <th>dist_z</th>\n",
       "      <th>molecule_couples</th>\n",
       "      <th>molecule_dist_mean</th>\n",
       "      <th>molecule_dist_min</th>\n",
       "      <th>molecule_dist_max</th>\n",
       "      <th>atom_0_couples_count</th>\n",
       "      <th>atom_1_couples_count</th>\n",
       "      <th>molecule_atom_index_0_x_1_std</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_y_1_mean_div</th>\n",
       "      <th>molecule_atom_index_0_y_1_max</th>\n",
       "      <th>molecule_atom_index_0_y_1_max_diff</th>\n",
       "      <th>molecule_atom_index_0_y_1_std</th>\n",
       "      <th>molecule_atom_index_0_z_1_std</th>\n",
       "      <th>molecule_atom_index_0_dist_mean</th>\n",
       "      <th>molecule_atom_index_0_dist_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_mean_div</th>\n",
       "      <th>molecule_atom_index_0_dist_max</th>\n",
       "      <th>molecule_atom_index_0_dist_max_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_max_div</th>\n",
       "      <th>molecule_atom_index_0_dist_min</th>\n",
       "      <th>molecule_atom_index_0_dist_min_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_min_div</th>\n",
       "      <th>molecule_atom_index_0_dist_std</th>\n",
       "      <th>molecule_atom_index_0_dist_std_diff</th>\n",
       "      <th>molecule_atom_index_0_dist_std_div</th>\n",
       "      <th>molecule_atom_index_1_dist_mean</th>\n",
       "      <th>molecule_atom_index_1_dist_mean_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_mean_div</th>\n",
       "      <th>molecule_atom_index_1_dist_max</th>\n",
       "      <th>molecule_atom_index_1_dist_max_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_max_div</th>\n",
       "      <th>molecule_atom_index_1_dist_min</th>\n",
       "      <th>molecule_atom_index_1_dist_min_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_min_div</th>\n",
       "      <th>molecule_atom_index_1_dist_std</th>\n",
       "      <th>molecule_atom_index_1_dist_std_diff</th>\n",
       "      <th>molecule_atom_index_1_dist_std_div</th>\n",
       "      <th>molecule_atom_1_dist_mean</th>\n",
       "      <th>molecule_atom_1_dist_min</th>\n",
       "      <th>molecule_atom_1_dist_min_diff</th>\n",
       "      <th>molecule_atom_1_dist_min_div</th>\n",
       "      <th>molecule_atom_1_dist_std</th>\n",
       "      <th>molecule_atom_1_dist_std_diff</th>\n",
       "      <th>molecule_type_0_dist_std</th>\n",
       "      <th>molecule_type_0_dist_std_diff</th>\n",
       "      <th>molecule_type_dist_mean</th>\n",
       "      <th>molecule_type_dist_mean_diff</th>\n",
       "      <th>molecule_type_dist_mean_div</th>\n",
       "      <th>molecule_type_dist_max</th>\n",
       "      <th>molecule_type_dist_min</th>\n",
       "      <th>molecule_type_dist_std</th>\n",
       "      <th>molecule_type_dist_std_diff</th>\n",
       "      <th>molecule_type_fc_max</th>\n",
       "      <th>molecule_type_fc_min</th>\n",
       "      <th>molecule_type_fc_std</th>\n",
       "      <th>molecule_type_fc_std_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_mean</th>\n",
       "      <th>molecule_atom_index_0_fc_mean_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_mean_div</th>\n",
       "      <th>molecule_atom_index_0_fc_max</th>\n",
       "      <th>molecule_atom_index_0_fc_max_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_max_div</th>\n",
       "      <th>molecule_atom_index_0_fc_min</th>\n",
       "      <th>molecule_atom_index_0_fc_min_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_min_div</th>\n",
       "      <th>molecule_atom_index_0_fc_std</th>\n",
       "      <th>molecule_atom_index_0_fc_std_diff</th>\n",
       "      <th>molecule_atom_index_0_fc_std_div</th>\n",
       "      <th>molecule_atom_index_1_fc_mean</th>\n",
       "      <th>molecule_atom_index_1_fc_mean_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_mean_div</th>\n",
       "      <th>molecule_atom_index_1_fc_max</th>\n",
       "      <th>molecule_atom_index_1_fc_max_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_max_div</th>\n",
       "      <th>molecule_atom_index_1_fc_min</th>\n",
       "      <th>molecule_atom_index_1_fc_min_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_min_div</th>\n",
       "      <th>molecule_atom_index_1_fc_std</th>\n",
       "      <th>molecule_atom_index_1_fc_std_diff</th>\n",
       "      <th>molecule_atom_index_1_fc_std_div</th>\n",
       "      <th>atom_index_closest_0</th>\n",
       "      <th>x_closest_0</th>\n",
       "      <th>y_closest_0</th>\n",
       "      <th>z_closest_0</th>\n",
       "      <th>atom_index_closest_1</th>\n",
       "      <th>x_closest_1</th>\n",
       "      <th>y_closest_1</th>\n",
       "      <th>z_closest_1</th>\n",
       "      <th>distance_0</th>\n",
       "      <th>distance_1</th>\n",
       "      <th>cos_0_1</th>\n",
       "      <th>cos_0</th>\n",
       "      <th>cos_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>-0.812772</td>\n",
       "      <td>0.773439</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.196234</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.201583</td>\n",
       "      <td>0.212813</td>\n",
       "      <td>H</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.644531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077596</td>\n",
       "      <td>3.251140</td>\n",
       "      <td>-3.093807</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>-0.813021</td>\n",
       "      <td>-0.784944</td>\n",
       "      <td>-0.067349</td>\n",
       "      <td>-0.806339</td>\n",
       "      <td>-0.851258</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>82.734236</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1.192105</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>10</td>\n",
       "      <td>1.506668</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.727907</td>\n",
       "      <td>1.358754</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>1.251380</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.182278</td>\n",
       "      <td>0.727957</td>\n",
       "      <td>1.610344</td>\n",
       "      <td>0.518391</td>\n",
       "      <td>1.474738</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>0.691204</td>\n",
       "      <td>1.632998</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345594</td>\n",
       "      <td>-0.746359</td>\n",
       "      <td>0.316492</td>\n",
       "      <td>1.09195</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.09195</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.091950</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>1.091950</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>84.195240</td>\n",
       "      <td>82.285655</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>-81.796736</td>\n",
       "      <td>12.468657</td>\n",
       "      <td>-70.265579</td>\n",
       "      <td>11.418675</td>\n",
       "      <td>82.734236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-11.096087</td>\n",
       "      <td>-93.830323</td>\n",
       "      <td>-0.134117</td>\n",
       "      <td>46.843908</td>\n",
       "      <td>-35.890328</td>\n",
       "      <td>0.566197</td>\n",
       "      <td>83.303123</td>\n",
       "      <td>0.568888</td>\n",
       "      <td>1.006876</td>\n",
       "      <td>84.195240</td>\n",
       "      <td>1.461004</td>\n",
       "      <td>1.017659</td>\n",
       "      <td>82.285655</td>\n",
       "      <td>-0.448581</td>\n",
       "      <td>0.994578</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-81.796736</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>1.091948</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>3</td>\n",
       "      <td>2.183905</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>-0.812772</td>\n",
       "      <td>0.773439</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.196234</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.201583</td>\n",
       "      <td>0.212813</td>\n",
       "      <td>H</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.161132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>-0.812776</td>\n",
       "      <td>0.773442</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.196235</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.201584</td>\n",
       "      <td>0.212813</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-10.987318</td>\n",
       "      <td>1</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.019253</td>\n",
       "      <td>2.160261</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>10</td>\n",
       "      <td>1.506668</td>\n",
       "      <td>1.091946</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727907</td>\n",
       "      <td>1.358754</td>\n",
       "      <td>-0.104998</td>\n",
       "      <td>0.928268</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182278</td>\n",
       "      <td>0.727957</td>\n",
       "      <td>1.610344</td>\n",
       "      <td>-0.172776</td>\n",
       "      <td>0.903105</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>1.000021</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>-0.691167</td>\n",
       "      <td>0.612383</td>\n",
       "      <td>0.345594</td>\n",
       "      <td>-1.437526</td>\n",
       "      <td>0.193814</td>\n",
       "      <td>1.78312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.783146</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783106</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783106</td>\n",
       "      <td>1.783146</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.000015</td>\n",
       "      <td>1.783158</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1.783106</td>\n",
       "      <td>-10.776204</td>\n",
       "      <td>-11.096087</td>\n",
       "      <td>0.112593</td>\n",
       "      <td>11.099910</td>\n",
       "      <td>12.468657</td>\n",
       "      <td>23.455974</td>\n",
       "      <td>6.992608</td>\n",
       "      <td>82.734236</td>\n",
       "      <td>93.721553</td>\n",
       "      <td>-7.529976</td>\n",
       "      <td>-11.096087</td>\n",
       "      <td>-0.108769</td>\n",
       "      <td>1.009900</td>\n",
       "      <td>46.843908</td>\n",
       "      <td>57.831225</td>\n",
       "      <td>-4.263453</td>\n",
       "      <td>-10.987318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-10.987318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-10.987318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>-0.333287</td>\n",
       "      <td>-0.816483</td>\n",
       "      <td>0.816482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_1  atom_index_0  atom_2  atom_3  atom_4  \\\n",
       "0   0  dsgdb9nsd_000001             0             1       1       1       1   \n",
       "1   1  dsgdb9nsd_000001             2             1       6       1       1   \n",
       "\n",
       "   atom_5  atom_6  atom_7  atom_8  atom_9     d_1_0     d_2_0     d_2_1  \\\n",
       "0       0       0       0       0       0  1.091953  1.783120  1.091952   \n",
       "1       0       0       0       0       0  1.783120  1.091953  1.091952   \n",
       "\n",
       "      d_3_0     d_3_1     d_3_2     d_4_0     d_4_1     d_4_2     d_4_3  \\\n",
       "0  1.783147  1.091946  1.783158  1.783157  1.091948  1.783148  1.783148   \n",
       "1  1.783157  1.783148  1.091948  1.783147  1.783158  1.091946  1.783148   \n",
       "\n",
       "   d_5_0  d_5_1  d_5_2  d_5_3  d_6_0  d_6_1  d_6_2  d_6_3  d_7_0  d_7_1  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   d_7_2  d_7_3  d_8_0  d_8_1  d_8_2  d_8_3  d_9_0  d_9_1  d_9_2  d_9_3  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   scalar_coupling_constant  type  dist_interact     eem_0  mmff94_0  \\\n",
       "0                   84.8076     0       1.091953  0.161131       0.0   \n",
       "1                  -11.2570     3       2.183905  0.161131       0.0   \n",
       "\n",
       "   gasteiger_0     qeq_0   qtpie_0  eem2015ha_0  eem2015hm_0  eem2015hn_0  \\\n",
       "0     0.019399 -0.812772  0.773439    -0.003651     0.203254     0.196234   \n",
       "1     0.019399 -0.812772  0.773439    -0.003651     0.203254     0.196234   \n",
       "\n",
       "   eem2015ba_0  eem2015bm_0  eem2015bn_0 atom_0      x_0       y_0       z_0  \\\n",
       "0     0.016837     0.201583     0.212813      H  0.00215 -0.006031  0.001976   \n",
       "1     0.016837     0.201583     0.212813      H  0.00215 -0.006031  0.001976   \n",
       "\n",
       "      eem_1  mmff94_1  gasteiger_1     qeq_1   qtpie_1  eem2015ha_1  \\\n",
       "0 -0.644531       0.0    -0.077596  3.251140 -3.093807     0.014606   \n",
       "1  0.161132       0.0     0.019399 -0.812776  0.773442    -0.003651   \n",
       "\n",
       "   eem2015hm_1  eem2015hn_1  eem2015ba_1  eem2015bm_1  eem2015bn_1  atom_1  \\\n",
       "0    -0.813021    -0.784944    -0.067349    -0.806339    -0.851258       0   \n",
       "1     0.203254     0.196235     0.016837     0.201584     0.212813       1   \n",
       "\n",
       "        x_1       y_1       z_1         fc  type_0      dist    dist_x  \\\n",
       "0 -0.012698  1.085804  0.008001  82.734236       0  1.091953  0.000220   \n",
       "1  1.011731  1.463751  0.000277 -10.987318       1  1.783120  1.019253   \n",
       "\n",
       "     dist_y    dist_z  molecule_couples  molecule_dist_mean  \\\n",
       "0  1.192105  0.000036                10            1.506668   \n",
       "1  2.160261  0.000003                10            1.506668   \n",
       "\n",
       "   molecule_dist_min  molecule_dist_max  atom_0_couples_count  \\\n",
       "0           1.091946           1.783158                     4   \n",
       "1           1.091946           1.783158                     4   \n",
       "\n",
       "   atom_1_couples_count  molecule_atom_index_0_x_1_std  \\\n",
       "0                     4                       0.727907   \n",
       "1                     1                       0.727907   \n",
       "\n",
       "   molecule_atom_index_0_y_1_mean  molecule_atom_index_0_y_1_mean_diff  \\\n",
       "0                        1.358754                             0.272949   \n",
       "1                        1.358754                            -0.104998   \n",
       "\n",
       "   molecule_atom_index_0_y_1_mean_div  molecule_atom_index_0_y_1_max  \\\n",
       "0                            1.251380                       1.463751   \n",
       "1                            0.928268                       1.463751   \n",
       "\n",
       "   molecule_atom_index_0_y_1_max_diff  molecule_atom_index_0_y_1_std  \\\n",
       "0                            0.377947                       0.182278   \n",
       "1                            0.000000                       0.182278   \n",
       "\n",
       "   molecule_atom_index_0_z_1_std  molecule_atom_index_0_dist_mean  \\\n",
       "0                       0.727957                         1.610344   \n",
       "1                       0.727957                         1.610344   \n",
       "\n",
       "   molecule_atom_index_0_dist_mean_diff  molecule_atom_index_0_dist_mean_div  \\\n",
       "0                              0.518391                             1.474738   \n",
       "1                             -0.172776                             0.903105   \n",
       "\n",
       "   molecule_atom_index_0_dist_max  molecule_atom_index_0_dist_max_diff  \\\n",
       "0                        1.783157                             0.691204   \n",
       "1                        1.783157                             0.000037   \n",
       "\n",
       "   molecule_atom_index_0_dist_max_div  molecule_atom_index_0_dist_min  \\\n",
       "0                            1.632998                        1.091953   \n",
       "1                            1.000021                        1.091953   \n",
       "\n",
       "   molecule_atom_index_0_dist_min_diff  molecule_atom_index_0_dist_min_div  \\\n",
       "0                             0.000000                            1.000000   \n",
       "1                            -0.691167                            0.612383   \n",
       "\n",
       "   molecule_atom_index_0_dist_std  molecule_atom_index_0_dist_std_diff  \\\n",
       "0                        0.345594                            -0.746359   \n",
       "1                        0.345594                            -1.437526   \n",
       "\n",
       "   molecule_atom_index_0_dist_std_div  molecule_atom_index_1_dist_mean  \\\n",
       "0                            0.316492                          1.09195   \n",
       "1                            0.193814                          1.78312   \n",
       "\n",
       "   molecule_atom_index_1_dist_mean_diff  molecule_atom_index_1_dist_mean_div  \\\n",
       "0                             -0.000003                             0.999997   \n",
       "1                              0.000000                             1.000000   \n",
       "\n",
       "   molecule_atom_index_1_dist_max  molecule_atom_index_1_dist_max_diff  \\\n",
       "0                        1.091953                                  0.0   \n",
       "1                        1.783120                                  0.0   \n",
       "\n",
       "   molecule_atom_index_1_dist_max_div  molecule_atom_index_1_dist_min  \\\n",
       "0                                 1.0                        1.091946   \n",
       "1                                 1.0                        1.783120   \n",
       "\n",
       "   molecule_atom_index_1_dist_min_diff  molecule_atom_index_1_dist_min_div  \\\n",
       "0                            -0.000007                            0.999994   \n",
       "1                             0.000000                            1.000000   \n",
       "\n",
       "   molecule_atom_index_1_dist_std  molecule_atom_index_1_dist_std_diff  \\\n",
       "0                        0.000003                             -1.09195   \n",
       "1                             NaN                                  NaN   \n",
       "\n",
       "   molecule_atom_index_1_dist_std_div  molecule_atom_1_dist_mean  \\\n",
       "0                            0.000003                   1.091950   \n",
       "1                                 NaN                   1.783146   \n",
       "\n",
       "   molecule_atom_1_dist_min  molecule_atom_1_dist_min_diff  \\\n",
       "0                  1.091946                      -0.000007   \n",
       "1                  1.783120                       0.000000   \n",
       "\n",
       "   molecule_atom_1_dist_min_div  molecule_atom_1_dist_std  \\\n",
       "0                      0.999994                  0.000003   \n",
       "1                      1.000000                  0.000014   \n",
       "\n",
       "   molecule_atom_1_dist_std_diff  molecule_type_0_dist_std  \\\n",
       "0                      -1.091950                  0.000003   \n",
       "1                      -1.783106                  0.000014   \n",
       "\n",
       "   molecule_type_0_dist_std_diff  molecule_type_dist_mean  \\\n",
       "0                      -1.091950                 1.091950   \n",
       "1                      -1.783106                 1.783146   \n",
       "\n",
       "   molecule_type_dist_mean_diff  molecule_type_dist_mean_div  \\\n",
       "0                     -0.000003                     0.999997   \n",
       "1                      0.000027                     1.000015   \n",
       "\n",
       "   molecule_type_dist_max  molecule_type_dist_min  molecule_type_dist_std  \\\n",
       "0                1.091953                1.091946                0.000003   \n",
       "1                1.783158                1.783120                0.000014   \n",
       "\n",
       "   molecule_type_dist_std_diff  molecule_type_fc_max  molecule_type_fc_min  \\\n",
       "0                    -1.091950             84.195240             82.285655   \n",
       "1                    -1.783106            -10.776204            -11.096087   \n",
       "\n",
       "   molecule_type_fc_std  molecule_type_fc_std_diff  \\\n",
       "0              0.937500                 -81.796736   \n",
       "1              0.112593                  11.099910   \n",
       "\n",
       "   molecule_atom_index_0_fc_mean  molecule_atom_index_0_fc_mean_diff  \\\n",
       "0                      12.468657                          -70.265579   \n",
       "1                      12.468657                           23.455974   \n",
       "\n",
       "   molecule_atom_index_0_fc_mean_div  molecule_atom_index_0_fc_max  \\\n",
       "0                          11.418675                     82.734236   \n",
       "1                           6.992608                     82.734236   \n",
       "\n",
       "   molecule_atom_index_0_fc_max_diff  molecule_atom_index_0_fc_max_div  \\\n",
       "0                           0.000000                          1.000000   \n",
       "1                          93.721553                         -7.529976   \n",
       "\n",
       "   molecule_atom_index_0_fc_min  molecule_atom_index_0_fc_min_diff  \\\n",
       "0                    -11.096087                         -93.830323   \n",
       "1                    -11.096087                          -0.108769   \n",
       "\n",
       "   molecule_atom_index_0_fc_min_div  molecule_atom_index_0_fc_std  \\\n",
       "0                         -0.134117                     46.843908   \n",
       "1                          1.009900                     46.843908   \n",
       "\n",
       "   molecule_atom_index_0_fc_std_diff  molecule_atom_index_0_fc_std_div  \\\n",
       "0                         -35.890328                          0.566197   \n",
       "1                          57.831225                         -4.263453   \n",
       "\n",
       "   molecule_atom_index_1_fc_mean  molecule_atom_index_1_fc_mean_diff  \\\n",
       "0                      83.303123                            0.568888   \n",
       "1                     -10.987318                            0.000000   \n",
       "\n",
       "   molecule_atom_index_1_fc_mean_div  molecule_atom_index_1_fc_max  \\\n",
       "0                           1.006876                     84.195240   \n",
       "1                           1.000000                    -10.987318   \n",
       "\n",
       "   molecule_atom_index_1_fc_max_diff  molecule_atom_index_1_fc_max_div  \\\n",
       "0                           1.461004                          1.017659   \n",
       "1                           0.000000                          1.000000   \n",
       "\n",
       "   molecule_atom_index_1_fc_min  molecule_atom_index_1_fc_min_diff  \\\n",
       "0                     82.285655                          -0.448581   \n",
       "1                    -10.987318                           0.000000   \n",
       "\n",
       "   molecule_atom_index_1_fc_min_div  molecule_atom_index_1_fc_std  \\\n",
       "0                          0.994578                        0.9375   \n",
       "1                          1.000000                           NaN   \n",
       "\n",
       "   molecule_atom_index_1_fc_std_diff  molecule_atom_index_1_fc_std_div  \\\n",
       "0                         -81.796736                          0.011331   \n",
       "1                                NaN                               NaN   \n",
       "\n",
       "   atom_index_closest_0  x_closest_0  y_closest_0  z_closest_0  \\\n",
       "0                     0    -0.012698     1.085804     0.008001   \n",
       "1                     0    -0.012698     1.085804     0.008001   \n",
       "\n",
       "   atom_index_closest_1  x_closest_1  y_closest_1  z_closest_1  distance_0  \\\n",
       "0                     3    -0.540815     1.447527    -0.876644    1.091953   \n",
       "1                     0    -0.012698     1.085804     0.008001    1.091953   \n",
       "\n",
       "   distance_1   cos_0_1     cos_0     cos_1  \n",
       "0    1.091946  0.333335 -1.000000 -0.333335  \n",
       "1    1.091952 -0.333287 -0.816483  0.816482  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'molecule_name', 'atom_index_1', 'atom_index_0', 'atom_2',\n",
      "       'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7',\n",
      "       ...\n",
      "       'z_closest_0', 'atom_index_closest_1', 'x_closest_1', 'y_closest_1',\n",
      "       'z_closest_1', 'distance_0', 'distance_1', 'cos_0_1', 'cos_0', 'cos_1'],\n",
      "      dtype='object', length=175)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['scalar_coupling_constant']\n",
    "train = train.drop(['id', 'molecule_name', 'atom_0', 'scalar_coupling_constant'], axis=1)\n",
    "test  =  test.drop(['id', 'molecule_name', 'atom_0'], axis=1)\n",
    "# train = reduce_mem_usage(train)\n",
    "# test  = reduce_mem_usage(test)\n",
    "\n",
    "X = train.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "assert len(X.columns) == len(X_test.columns), f'X と X_test のサイズが違います X: {len(X.columns)}, X_test: {len(X_test.columns)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test, full_train, full_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TARGET = 'scalar_coupling_constant'\n",
    "CAT_FEATS = ['type']\n",
    "N_ESTIMATORS = 3000\n",
    "VERBOSE = 0\n",
    "EARLY_STOPPING_ROUNDS = 200\n",
    "RANDOM_STATE = 529\n",
    "METRIC = mean_absolute_error\n",
    "N_JOBS = 60\n",
    "random_state_list = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41]\n",
    "\n",
    "# lightgbm params from nb55\n",
    "# lgb_params = {'num_leaves': 128,\n",
    "#           'min_child_samples': 79,\n",
    "#           'objective': 'regression',\n",
    "#           'max_depth': 9,\n",
    "#           'learning_rate': 0.2,\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"subsample_freq\": 1,\n",
    "#           \"subsample\": 0.9,\n",
    "#           \"bagging_seed\": 11,\n",
    "#           \"metric\": 'mae',\n",
    "#           \"verbosity\": -1,\n",
    "#           'reg_alpha': 0.1,\n",
    "#           'reg_lambda': 0.3,\n",
    "#           'colsample_bytree': 1.0\n",
    "#          }\n",
    "\n",
    "lgb_params_list =  [\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 70,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.1,\n",
    "  'reg_lambda': 0.6,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.8,\n",
    "  'learning_rate': 0.1,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 70,\n",
    "  'num_leaves': 100,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.4,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.8,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 45,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.6,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.1,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 20,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.2,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 0.3,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.8,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 70,\n",
    "  'num_leaves': 100,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.1,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 20,\n",
    "  'num_leaves': 100,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.6,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 0.6,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 100,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.2,\n",
    "  'reg_lambda': 0.4,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1},\n",
    " {'bagging_seed': 11,\n",
    "  'boosting': 'gbdt',\n",
    "  'colsample_bytree': 1,\n",
    "  'learning_rate': 0.3,\n",
    "  'max_depth': 15,\n",
    "  'metric': 'mae',\n",
    "  'min_child_samples': 45,\n",
    "  'num_leaves': 250,\n",
    "  'objective': 'regression',\n",
    "  'reg_alpha': 0.2,\n",
    "  'reg_lambda': 0.2,\n",
    "  'subsample': 1,\n",
    "  'subsample_freq': 1,\n",
    "  'verbosity': -1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "\n",
    "def train_lgb(X, X_test, y, lgb_params, folds,\n",
    "              verbose, early_stopping_rounds, n_estimators, categorical_feature=None, random_state=42):\n",
    "\n",
    "    result_dict = {}\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    models = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_idx, valid_idx) in enumerate(folds.split(X)):\n",
    "#         print('------------------')\n",
    "#         print(f'- fold{fold_n + 1}' )\n",
    "#         print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        \n",
    "\n",
    "        # Train the model\n",
    "        model = lgb.LGBMRegressor(**lgb_params, n_estimators=n_estimators, n_jobs=N_JOBS, random_state=random_state)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=verbose,\n",
    "                  early_stopping_rounds=early_stopping_rounds,\n",
    "                  categorical_feature=CAT_FEATS)\n",
    "\n",
    "        # predict\n",
    "        y_valid_pred = model.predict(X_valid, num_iteration=model.best_iteration_)   \n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        oof[valid_idx] = y_valid_pred.reshape(-1,)  # oof: out of folds\n",
    "        scores.append(mean_absolute_error(y_valid, y_valid_pred))\n",
    "\n",
    "        prediction += y_test_pred\n",
    "\n",
    "        # feature_importance\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance['feature'] = X.columns\n",
    "        fold_importance['importance'] = model.feature_importances_\n",
    "        fold_importance['fold'] = fold_n + 1\n",
    "        feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    # result\n",
    "    prediction /= folds.n_splits\n",
    "    feature_importance[\"importance\"] /= folds.n_splits\n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    result_dict['feature_importance'] = feature_importance\n",
    "\n",
    "\n",
    "#     print('------------------')\n",
    "#     print('====== finish ======')\n",
    "#     print('score list:', scores)\n",
    "    X['scalar_coupling_constant'] = y\n",
    "    cv_score = kaggle_metric(X, oof)\n",
    "    X = X.drop(['scalar_coupling_constant', 'prediction'], axis=1)\n",
    "#     print('CV mean score(group log mae): {0:.4f}'.format(cv_score))\n",
    "#     print('')\n",
    "\n",
    "    \n",
    "    return result_dict, cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 6\n",
    "folds = KFold(n_splits=n_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===================== random_state: 2 ============================\n",
      " - started at Fri Aug 23 10:05:51 2019\n",
      "CV mean score(group log mae): -1.5231\n",
      "save pash: ../output/nb66_submission_lgb_-1.5230786851984113.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5230786851984113.csv\n",
      "\n",
      " ===================== random_state: 3 ============================\n",
      " - started at Fri Aug 23 11:44:40 2019\n",
      "CV mean score(group log mae): -1.5259\n",
      "save pash: ../output/nb66_submission_lgb_-1.525949229397984.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.525949229397984.csv\n",
      "\n",
      " ===================== random_state: 5 ============================\n",
      " - started at Fri Aug 23 13:24:14 2019\n",
      "CV mean score(group log mae): -1.5108\n",
      "save pash: ../output/nb66_submission_lgb_-1.5108102403066945.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5108102403066945.csv\n",
      "\n",
      " ===================== random_state: 7 ============================\n",
      " - started at Fri Aug 23 15:03:38 2019\n",
      "CV mean score(group log mae): -1.5222\n",
      "save pash: ../output/nb66_submission_lgb_-1.522247972248535.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.522247972248535.csv\n",
      "\n",
      " ===================== random_state: 11 ============================\n",
      " - started at Fri Aug 23 16:43:18 2019\n",
      "CV mean score(group log mae): -1.5237\n",
      "save pash: ../output/nb66_submission_lgb_-1.5237066201155227.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5237066201155227.csv\n",
      "\n",
      " ===================== random_state: 13 ============================\n",
      " - started at Fri Aug 23 18:22:29 2019\n",
      "CV mean score(group log mae): -1.5185\n",
      "save pash: ../output/nb66_submission_lgb_-1.5185134763153392.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5185134763153392.csv\n",
      "\n",
      " ===================== random_state: 17 ============================\n",
      " - started at Fri Aug 23 20:02:01 2019\n",
      "CV mean score(group log mae): -1.5238\n",
      "save pash: ../output/nb66_submission_lgb_-1.5237776143751525.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5237776143751525.csv\n",
      "\n",
      " ===================== random_state: 19 ============================\n",
      " - started at Fri Aug 23 21:41:47 2019\n",
      "CV mean score(group log mae): -1.5257\n",
      "save pash: ../output/nb66_submission_lgb_-1.5256732179582444.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5256732179582444.csv\n",
      "\n",
      " ===================== random_state: 23 ============================\n",
      " - started at Fri Aug 23 23:21:28 2019\n",
      "CV mean score(group log mae): -1.5257\n",
      "save pash: ../output/nb66_submission_lgb_-1.525680526554059.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.525680526554059.csv\n",
      "\n",
      " ===================== random_state: 29 ============================\n",
      " - started at Sat Aug 24 01:01:05 2019\n",
      "CV mean score(group log mae): -1.5214\n",
      "save pash: ../output/nb66_submission_lgb_-1.5214483439586213.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5214483439586213.csv\n",
      "\n",
      " ===================== random_state: 31 ============================\n",
      " - started at Sat Aug 24 02:40:37 2019\n",
      "CV mean score(group log mae): -1.5117\n",
      "save pash: ../output/nb66_submission_lgb_-1.5117177588853563.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5117177588853563.csv\n",
      "\n",
      " ===================== random_state: 37 ============================\n",
      " - started at Sat Aug 24 04:19:50 2019\n",
      "CV mean score(group log mae): -1.5250\n",
      "save pash: ../output/nb66_submission_lgb_-1.5249982332452774.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5249982332452774.csv\n",
      "\n",
      " ===================== random_state: 41 ============================\n",
      " - started at Sat Aug 24 05:59:22 2019\n",
      "CV mean score(group log mae): -1.5174\n",
      "save pash: ../output/nb66_submission_lgb_-1.5173988287698.csv\n",
      "save pash: ../output/nb66_oof_lgb_-1.5173988287698.csv\n",
      "CPU times: user 47d 22h 3min 52s, sys: 9h 41s, total: 48d 7h 4min 33s\n",
      "Wall time: 21h 33min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# type ごとの学習 \n",
    "\n",
    "for rs in random_state_list:\n",
    "    \n",
    "    print(f'\\n ===================== random_state: {rs} ============================')\n",
    "    print(f' - started at {time.ctime()}')\n",
    "    feature_importance  = pd.DataFrame()\n",
    "    X_short = pd.DataFrame({'ind': list(X.index), 'type': X['type'].values, 'oof': [0] * len(X), 'target': y.values})\n",
    "    X_short_test = pd.DataFrame({'ind': list(X_test.index), 'type': X_test['type'].values, 'prediction': [0] * len(X_test)})\n",
    "    for t in X['type'].unique():\n",
    "#         print('*'*80)\n",
    "#         print(f'Training of type {t}')\n",
    "#         print('*'*80)\n",
    "        lgb_params = lgb_params_list[t]\n",
    "        X_t = X.loc[X['type'] == t]\n",
    "        X_test_t = X_test.loc[X_test['type'] == t]\n",
    "        y_t = X_short.loc[X_short['type'] == t, 'target'].values\n",
    "        result_dict, cv_score = train_lgb(X=X_t, X_test=X_test_t, y=y_t, folds=folds, lgb_params=lgb_params,\n",
    "                                verbose=VERBOSE, early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                                n_estimators=N_ESTIMATORS,\n",
    "                                categorical_feature=CAT_FEATS, random_state=rs)\n",
    "        X_short.loc[X_short['type'] == t, 'oof'] = result_dict['oof']\n",
    "        X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict['prediction']\n",
    "\n",
    "        feature_importance = pd.concat([feature_importance, result_dict['feature_importance']], axis=0)\n",
    "\n",
    "    X['scalar_coupling_constant'] = y\n",
    "    metric = kaggle_metric(X, X_short['oof'])\n",
    "    X = X.drop(['scalar_coupling_constant', 'prediction'], axis=1)\n",
    "    print('CV mean score(group log mae): {0:.4f}'.format(metric))\n",
    "    prediction = X_short_test['prediction']\n",
    "    \n",
    "    # save\n",
    "    # submission\n",
    "    path_submittion = '../output/nb{}_submission_lgb_{}.csv'.format(nb, metric)\n",
    "    print(f'save pash: {path_submittion}')\n",
    "    if not isSmallSet:\n",
    "        submittion = pd.read_csv('../input/champs-scalar-coupling/sample_submission.csv')\n",
    "        submittion['scalar_coupling_constant'] = prediction\n",
    "        submittion.to_csv(path_submittion, index=False)\n",
    "    \n",
    "    # oof\n",
    "    path_oof = '../output/' + 'nb{}_oof_lgb_{}.csv'.format(nb, metric)\n",
    "    print(f'save pash: {path_oof}')\n",
    "    if not isSmallSet:\n",
    "        oof = pd.DataFrame(X_short['oof'])\n",
    "        oof.to_csv(path_oof, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
